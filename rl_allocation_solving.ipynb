{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8609776d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pulp\n",
    "# import pandas as pd\n",
    "# # from pylab import *\n",
    "# import matplotlib\n",
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "# np.random.seed(1)\n",
    "# import os\n",
    "\n",
    "# styles = [\"A\",\"B\",\"C\"]\n",
    "# colors= [\"R\", \"B\", \"G\"]\n",
    "# shops = [\"1\",\"2\",\"3\"]\n",
    "# bundles = [str(i+1) for i in range(13)]\n",
    "\n",
    "\n",
    "# bundles_static={\n",
    "#     \"1\":{\"AR\":1,\"AB\":1,\"AG\":1,\"BR\":1,\"BB\":1,\"BG\":1,\"CR\":1,\"CB\":1,\"CG\":1},\n",
    "#     \"2\":{\"AR\":3,\"AB\":3,\"AG\":3,\"BR\":0,\"BB\":0,\"BG\":0,\"CR\":0,\"CB\":0,\"CG\":0},\n",
    "#     \"3\":{\"AR\":0,\"AB\":0,\"AG\":0,\"BR\":3,\"BB\":3,\"BG\":3,\"CR\":0,\"CB\":0,\"CG\":0},\n",
    "#     \"4\":{\"AR\":0,\"AB\":0,\"AG\":0,\"BR\":0,\"BB\":0,\"BG\":0,\"CR\":3,\"CB\":3,\"CG\":3},\n",
    "#     \"5\":{\"AR\":1,\"AB\":0,\"AG\":0,\"BR\":0,\"BB\":0,\"BG\":0,\"CR\":0,\"CB\":0,\"CG\":0},\n",
    "#     \"6\":{\"AR\":0,\"AB\":1,\"AG\":0,\"BR\":0,\"BB\":0,\"BG\":0,\"CR\":0,\"CB\":0,\"CG\":0},\n",
    "#     \"7\":{\"AR\":0,\"AB\":0,\"AG\":1,\"BR\":0,\"BB\":0,\"BG\":0,\"CR\":0,\"CB\":0,\"CG\":0},\n",
    "#     \"8\":{\"AR\":0,\"AB\":0,\"AG\":0,\"BR\":1,\"BB\":0,\"BG\":0,\"CR\":0,\"CB\":0,\"CG\":0},\n",
    "#     \"9\":{\"AR\":0,\"AB\":0,\"AG\":0,\"BR\":0,\"BB\":1,\"BG\":0,\"CR\":0,\"CB\":0,\"CG\":0},\n",
    "#     \"10\":{\"AR\":0,\"AB\":0,\"AG\":0,\"BR\":0,\"BB\":0,\"BG\":1,\"CR\":0,\"CB\":0,\"CG\":0},\n",
    "#     \"11\":{\"AR\":0,\"AB\":0,\"AG\":0,\"BR\":0,\"BB\":0,\"BG\":0,\"CR\":1,\"CB\":0,\"CG\":0},\n",
    "#     \"12\":{\"AR\":0,\"AB\":0,\"AG\":0,\"BR\":0,\"BB\":0,\"BG\":0,\"CR\":0,\"CB\":1,\"CG\":0},\n",
    "#     \"13\":{\"AR\":0,\"AB\":0,\"AG\":0,\"BR\":0,\"BB\":0,\"BG\":0,\"CR\":0,\"CB\":0,\"CG\":1}\n",
    "# }\n",
    "\n",
    "\n",
    "# budget = 1000\n",
    "# bundle_cost = 10\n",
    "# desired_allocation = 40\n",
    "\n",
    "# # bundle_availability = {\"1\":10,\"2\":10,\"3\":10,\"4\":60}\n",
    "# bundle_availability = {str(i+1):np.random.randint(5,20) for i in range(13)}\n",
    "\n",
    "\n",
    "# inventory_diff = []\n",
    "# current_inventory = {}\n",
    "# for i,shop in enumerate(shops):\n",
    "#     current_inventory[shop] = {}\n",
    "#     for style in styles:\n",
    "#         for color in colors:\n",
    "#             current_inventory[shop][style+color] = np.random.randint(0,10)\n",
    "#             for i in range(-50,50):\n",
    "#                 inventory_diff.append((shop,style+color,i))\n",
    "\n",
    "\n",
    "# bundle_allocation = []\n",
    "# #bundle k1\n",
    "# for k1 in bundles_static.keys():\n",
    "#     #shop+color k2\n",
    "#     for k2 in bundles_static[k1].keys():\n",
    "#         bundle_allocation.append((k1,k2))\n",
    "        \n",
    "# inventory_allocation = []\n",
    "# for shop in shops:\n",
    "#     for bundle in bundles:\n",
    "#         inventory_allocation.append((shop,bundle))\n",
    "\n",
    "\n",
    "# p_b_var = pulp.LpVariable.dicts('bundle_gather', bundles,lowBound=0, cat=\"Integer\")\n",
    "# p_ba_var = pulp.LpVariable.dicts('bundle_alloc', bundle_allocation,lowBound=0, cat=\"Integer\")\n",
    "# p_id_var = pulp.LpVariable.dicts('inventory_diff', inventory_diff, cat=\"Binary\")\n",
    "# p_ia_var = pulp.LpVariable.dicts('inventory_alloc', inventory_allocation,lowBound=0, cat=\"Integer\")\n",
    "\n",
    "# model = pulp.LpProblem(\"opt_inventory\", pulp.LpMaximize)\n",
    "\n",
    "# cost_obj = pulp.lpSum(p_b_var)\n",
    "\n",
    "# cost_obj\n",
    "\n",
    "# model+=cost_obj\n",
    "\n",
    "# for bundle in bundles:\n",
    "#     model+=bundle_availability[bundle]-p_b_var[bundle] >= 0\n",
    "           \n",
    "\n",
    "# for shop in shops:\n",
    "#     for style in styles:\n",
    "#         for color in colors:\n",
    "#             constr=[]\n",
    "#             for i in range(-50,50):\n",
    "#                 constr.append(p_id_var[(shop,style+color,i)])\n",
    "#             model += pulp.lpSum(constr)==1\n",
    "\n",
    "# for bundle in bundles_static:\n",
    "    \n",
    "#     for style in styles:\n",
    "#         for color in colors:\n",
    "#             #constraint on bundle and allocation\n",
    "#             model += p_b_var[bundle]*bundles_static[bundle][style+color]==p_ba_var[bundle,style+color]\n",
    "    \n",
    "#     ia_constr = []        \n",
    "#     for shop in shops:         \n",
    "#         ia_constr.append(p_ia_var[shop,bundle])\n",
    "#     #make sure that the all distributor bundles are sent to shops\n",
    "#     model += p_b_var[bundle]==pulp.lpSum(ia_constr)\n",
    "\n",
    "\n",
    "# #efficiency of allocation\n",
    "# allocation_eff = []\n",
    "# for shop in shops:\n",
    "#     for style in styles:\n",
    "#         for color in colors:\n",
    "#             sc_units = current_inventory[shop][style+color]\n",
    "#             for bundle in bundles:\n",
    "#                 sc_units += p_ia_var[(shop,bundle)]*bundles_static[bundle][style+color] \n",
    "            \n",
    "#             #allocated bundles*number of shirts in bundle_id for each style color\n",
    "#             loss = sc_units - desired_allocation\n",
    "#             #ensure it does not go over the desired allocation\n",
    "#             model+= loss <= 49\n",
    "#             model+= loss >= -50\n",
    "\n",
    "#             allocation_eff.append(loss)\n",
    "            \n",
    "            \n",
    "#             id_var_constr = []\n",
    "#             for i in range(-50,50):\n",
    "#                 id_var_constr.append(p_id_var[(shop,style+color,i)]*i)\n",
    "            \n",
    "#             model+=pulp.lpSum(id_var_constr)==loss\n",
    "        \n",
    "# non_lin = [np.sqrt(i**2) for i in range(-50,50)]\n",
    "\n",
    "\n",
    "# custom_alloc_eff = []\n",
    "# i=0\n",
    "# for shop in shops:\n",
    "#     for style in styles:\n",
    "#         for color in colors:\n",
    "#             new_loss = 0\n",
    "#             for j in range(-50,50):\n",
    "#                 new_loss+=p_id_var[(shop,style+color,j)]*non_lin[j]\n",
    "#             custom_alloc_eff.append(new_loss)\n",
    "#             i+=1\n",
    "\n",
    "# allocation_obj = pulp.lpSum(custom_alloc_eff)\n",
    "\n",
    "# model+=allocation_obj\n",
    "\n",
    "# solution = model.solve()\n",
    "\n",
    "# print(\"The Objective Value\", pulp.value(model.objective))\n",
    "\n",
    "\n",
    "\n",
    "# diff_inventory_df = pd.DataFrame(columns=('shop_id','style','color','diff','loss'))\n",
    "# j=0\n",
    "# for shop in shops:\n",
    "#     for style in styles:\n",
    "#         for color in colors:\n",
    "#             for i in range(-50,50):\n",
    "#                 if p_id_var[shop,style+color,i].value()>0:\n",
    "#                     diff_inventory_df.loc[j]=[shop,style,color,p_id_var[shop,style+color,i].value(),i]\n",
    "#                     j+=1\n",
    "                \n",
    "# diff_inventory_df      \n",
    "\n",
    "# current_inventory_df = pd.DataFrame(columns=('shop_id','style','color','sc_units'))\n",
    "# updated_inventory_df = pd.DataFrame(columns=('shop_id','style','color','sc_units'))\n",
    "\n",
    "# i=0\n",
    "# for shop in shops:\n",
    "#     for style in styles:\n",
    "#         for color in colors:\n",
    "#             sc_units = current_inventory[shop][style+color]\n",
    "#             current_inventory_df.loc[i]=[shop,style,color,sc_units]\n",
    "            \n",
    "#             for bundle in bundles:\n",
    "#                 sc_units += p_ia_var[shop,bundle].value()*bundles_static[bundle][style+color] \n",
    "                    \n",
    "#             updated_inventory_df.loc[i]=[shop,style,color,sc_units]\n",
    "#             i+=1\n",
    "\n",
    "# shop_bundle_proba_df = pd.DataFrame(columns=('shop_id','bundle_id','proba'))\n",
    "# shop_bundle_df = pd.DataFrame(columns=('shop_id','bundle_id','bundle_units'))\n",
    "\n",
    "# i=0\n",
    "# for shop in shops:\n",
    "#     for bundle in bundles:\n",
    "#         shop_bundle_df.loc[i] = [shop,bundle,p_ia_var[shop, bundle].value()]\n",
    "#         shop_bundle_proba_df.loc[i] = [shop,bundle,np.random.uniform(0,1)]\n",
    "#         i+=1\n",
    "\n",
    "# alloc_bundle_df = pd.DataFrame(columns=('bundle_id','alloc_bundles'))\n",
    "# i=0\n",
    "# for bundle in bundles:\n",
    "\n",
    "#     alloc_bundle_df.loc[i] = [bundle,p_b_var[bundle].value()]\n",
    "#     i+=1\n",
    "\n",
    "# avail_bundle_df = pd.DataFrame(columns=('bundle_id','avail_bundles'))\n",
    "# i=0\n",
    "# for bundle in bundles:\n",
    "\n",
    "#     avail_bundle_df.loc[i] = [bundle,bundle_availability[bundle]]\n",
    "#     i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "63e155f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bundle_lookup_df = pd.DataFrame(bundles_static).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ac1695b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# avail_bundle_vec = avail_bundle_df['avail_bundles'].values\n",
    "# avail_bundle_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e5e8d19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inventory_vec = current_inventory_df['sc_units'].values\n",
    "\n",
    "# inventory_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c002e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pulp\n",
    "import pandas as pd\n",
    "# from pylab import *\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "np.random.seed(1)\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "619e81cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "    # Disable all GPUS\n",
    "tf.config.set_visible_devices([], 'GPU')\n",
    "visible_devices = tf.config.get_visible_devices()\n",
    "visible_devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ae3c16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1b21219a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class OptBlock(tf.keras.Model):\n",
    "    def __init__(self,seed=1, use_mip_solver=True, shuffle_bundles=False):\n",
    "        super(OptBlock,self).__init__(name='')\n",
    "\n",
    "\n",
    "        np.random.seed(seed)\n",
    "        self.styles = [\"A\",\"B\",\"C\"]\n",
    "        self.colors= [\"R\", \"B\", \"G\"]\n",
    "        self.shops = [\"1\",\"2\",\"3\"]\n",
    "        self.bundles = [str(i+1) for i in range(13)]\n",
    "        \n",
    "        self.bundles_static={\n",
    "            \"1\":{\"AR\":1,\"AB\":1,\"AG\":1,\"BR\":1,\"BB\":1,\"BG\":1,\"CR\":1,\"CB\":1,\"CG\":1},\n",
    "            \"2\":{\"AR\":3,\"AB\":3,\"AG\":3,\"BR\":0,\"BB\":0,\"BG\":0,\"CR\":0,\"CB\":0,\"CG\":0},\n",
    "            \"3\":{\"AR\":0,\"AB\":0,\"AG\":0,\"BR\":3,\"BB\":3,\"BG\":3,\"CR\":0,\"CB\":0,\"CG\":0},\n",
    "            \"4\":{\"AR\":0,\"AB\":0,\"AG\":0,\"BR\":0,\"BB\":0,\"BG\":0,\"CR\":3,\"CB\":3,\"CG\":3},\n",
    "            \"5\":{\"AR\":1,\"AB\":0,\"AG\":0,\"BR\":0,\"BB\":0,\"BG\":0,\"CR\":0,\"CB\":0,\"CG\":0},\n",
    "            \"6\":{\"AR\":0,\"AB\":1,\"AG\":0,\"BR\":0,\"BB\":0,\"BG\":0,\"CR\":0,\"CB\":0,\"CG\":0},\n",
    "            \"7\":{\"AR\":0,\"AB\":0,\"AG\":1,\"BR\":0,\"BB\":0,\"BG\":0,\"CR\":0,\"CB\":0,\"CG\":0},\n",
    "            \"8\":{\"AR\":0,\"AB\":0,\"AG\":0,\"BR\":1,\"BB\":0,\"BG\":0,\"CR\":0,\"CB\":0,\"CG\":0},\n",
    "            \"9\":{\"AR\":0,\"AB\":0,\"AG\":0,\"BR\":0,\"BB\":1,\"BG\":0,\"CR\":0,\"CB\":0,\"CG\":0},\n",
    "            \"10\":{\"AR\":0,\"AB\":0,\"AG\":0,\"BR\":0,\"BB\":0,\"BG\":1,\"CR\":0,\"CB\":0,\"CG\":0},\n",
    "            \"11\":{\"AR\":0,\"AB\":0,\"AG\":0,\"BR\":0,\"BB\":0,\"BG\":0,\"CR\":1,\"CB\":0,\"CG\":0},\n",
    "            \"12\":{\"AR\":0,\"AB\":0,\"AG\":0,\"BR\":0,\"BB\":0,\"BG\":0,\"CR\":0,\"CB\":1,\"CG\":0},\n",
    "            \"13\":{\"AR\":0,\"AB\":0,\"AG\":0,\"BR\":0,\"BB\":0,\"BG\":0,\"CR\":0,\"CB\":0,\"CG\":1}\n",
    "        }\n",
    "\n",
    "        \n",
    "        if shuffle_bundles==True:\n",
    "            keys = list(self.bundles_static.keys())\n",
    "            np.random.shuffle(keys)\n",
    "            self.bundles_static = {str(i+1):self.bundles_static[key] for i,key in enumerate(keys)}\n",
    "            \n",
    "            \n",
    "        for i in range(13):\n",
    "#             self.bundles_static[str(i+1)]={}\n",
    "            for style in self.styles:\n",
    "                for color in self.colors:\n",
    "                    self.bundles_static[str(i+1)][style+color] = max(0,self.bundles_static[str(i+1)][style+color]+np.random.randint(-1,2))\n",
    "        \n",
    "\n",
    "        # bundle_availability = {\"1\":10,\"2\":10,\"3\":10,\"4\":60}\n",
    "        self.bundle_availability = {str(i+1):np.random.randint(5,20) for i in range(13)}\n",
    "\n",
    "\n",
    "        self.inventory_diff = []\n",
    "        self.current_inventory = {}\n",
    "        self.desired_allocation = {}\n",
    "        for i,shop in enumerate(self.shops):\n",
    "            self.current_inventory[shop] = {}\n",
    "            self.desired_allocation[shop] = {}\n",
    "            for style in self.styles:\n",
    "                for color in self.colors:\n",
    "                    self.current_inventory[shop][style+color] = np.random.randint(0,10)\n",
    "                    self.desired_allocation[shop][style+color] = self.current_inventory[shop][style+color]+np.random.randint(0,60)\n",
    "                    for i in range(-50,50):\n",
    "                        self.inventory_diff.append((shop,style+color,i))\n",
    "\n",
    "\n",
    "        self.bundle_allocation = []\n",
    "        #bundle k1\n",
    "        for k1 in self.bundles_static.keys():\n",
    "            #shop+color k2\n",
    "            for k2 in self.bundles_static[k1].keys():\n",
    "                self.bundle_allocation.append((k1,k2))\n",
    "\n",
    "        self.inventory_allocation = []\n",
    "        for shop in self.shops:\n",
    "            for bundle in self.bundles:\n",
    "                self.inventory_allocation.append((shop,bundle))\n",
    "        \n",
    "\n",
    "#         diff_inventory_df = pd.DataFrame(columns=('shop_id','style','color','diff','loss'))\n",
    "#         j=0\n",
    "#         for shop in shops:\n",
    "#             for style in styles:\n",
    "#                 for color in colors:\n",
    "#                     for i in range(-50,50):\n",
    "#                         if p_id_var[shop,style+color,i].value()>0:\n",
    "#                             diff_inventory_df.loc[j]=[shop,style,color,p_id_var[shop,style+color,i].value(),i]\n",
    "#                             j+=1\n",
    "        if use_mip_solver==True:\n",
    "            self.run_mip()\n",
    "        self.create_tf_vars(from_mip_sol=use_mip_solver)\n",
    "\n",
    "    def create_tf_vars(self,from_mip_sol=True):\n",
    "        self.tf_cur_inven = {}\n",
    "        self.mip_upd_inven = {}\n",
    "        self.tf_des_alloc = {}\n",
    "        self.target = []\n",
    "        \n",
    "        for shop in self.shops:\n",
    "            self.tf_cur_inven[shop] = {}\n",
    "            self.mip_upd_inven[shop] = {}\n",
    "            self.tf_des_alloc[shop] = {}\n",
    "            for style in self.styles:\n",
    "                for color in self.colors:\n",
    "                    sc_units = self.current_inventory[shop][style+color]\n",
    "                    self.tf_cur_inven[shop][style+color] = tf.cast(self.current_inventory[shop][style+color],tf.float32)\n",
    "                    self.tf_des_alloc[shop][style+color] = tf.cast(self.desired_allocation[shop][style+color],tf.float32)\n",
    "                    if from_mip_sol==True:\n",
    "                        for bundle in self.bundles:\n",
    "                            sc_units += self.p_ia_var[shop,bundle].value()*self.bundles_static[bundle][style+color] \n",
    "\n",
    "                        self.mip_upd_inven[shop][style+color] = tf.cast(sc_units,tf.float32)\n",
    "                        self.target.append([self.mip_upd_inven[shop][style+color]])\n",
    "                    else:\n",
    "                        self.target.append([self.tf_des_alloc[shop][style+color]])\n",
    "                \n",
    "        self.target = tf.reshape(tf.concat(self.target,axis=0),[1,-1])\n",
    "\n",
    "        self.tf_proba = {}\n",
    "        self.mip_shop_bundle = {}\n",
    "        self.tf_alloc_shp_bun = {}\n",
    "        i=0\n",
    "        for shop in self.shops:\n",
    "            for bundle in self.bundles:\n",
    "                self.tf_proba[(shop,bundle)] = tf.cast(0.0,tf.float32)\n",
    "                self.tf_alloc_shp_bun[(shop,bundle)] = tf.cast(0.0,tf.float32)\n",
    "                if from_mip_sol==True:\n",
    "                    self.mip_shop_bundle[(shop,bundle)] = tf.cast(self.p_ia_var[shop, bundle].value(),tf.float32)\n",
    "\n",
    "\n",
    "\n",
    "        self.mip_alloc_bundle = {}                \n",
    "        self.tf_alloc_bundle = {}\n",
    "        self.tf_avail_bundle = {}\n",
    "        \n",
    "        for bundle in self.bundles:\n",
    "            if from_mip_sol==True:\n",
    "                self.mip_alloc_bundle[bundle] = tf.cast(self.p_b_var[bundle].value(),tf.float32)\n",
    "            self.tf_alloc_bundle[bundle] = tf.cast(0.0,tf.float32)\n",
    "            self.tf_avail_bundle[bundle] =  tf.cast(self.bundle_availability[bundle],tf.float32)\n",
    "        \n",
    "        self.tf_bun_sty_col = {}\n",
    "        for bundle in self.bundles:\n",
    "            self.tf_bun_sty_col[bundle] = {}\n",
    "            for style in self.styles:\n",
    "                for color in self.colors:\n",
    "                    self.tf_bun_sty_col[bundle][style+color] = tf.cast(self.bundles_static[bundle][style+color],tf.float32)\n",
    "                \n",
    "    def run_mip(self):\n",
    "\n",
    "        self.p_b_var = pulp.LpVariable.dicts('bundle_gather', self.bundles,lowBound=0, cat=\"Integer\")\n",
    "        self.p_ba_var = pulp.LpVariable.dicts('bundle_alloc', self.bundle_allocation,lowBound=0, cat=\"Integer\")\n",
    "        self.p_id_var = pulp.LpVariable.dicts('inventory_diff', self.inventory_diff, cat=\"Binary\")\n",
    "        self.p_ia_var = pulp.LpVariable.dicts('inventory_alloc', self.inventory_allocation,lowBound=0, cat=\"Integer\")\n",
    "\n",
    "        model = pulp.LpProblem(\"opt_inventory\", pulp.LpMaximize)\n",
    "\n",
    "        cost_obj = pulp.lpSum(self.p_b_var)\n",
    "\n",
    "        cost_obj\n",
    "\n",
    "        model+=cost_obj\n",
    "        \n",
    "        for bundle in self.bundles:\n",
    "            model+=self.bundle_availability[bundle]-self.p_b_var[bundle] >= 0\n",
    "\n",
    "\n",
    "        for shop in self.shops:\n",
    "            for style in self.styles:\n",
    "                for color in self.colors:\n",
    "                    constr=[]\n",
    "                    for i in range(-50,50):\n",
    "                        constr.append(self.p_id_var[(shop,style+color,i)])\n",
    "                    model += pulp.lpSum(constr)==1\n",
    "\n",
    "        for bundle in self.bundles_static:\n",
    "\n",
    "            for style in self.styles:\n",
    "                for color in self.colors:\n",
    "                    #constraint on bundle and allocation\n",
    "                    model += self.p_b_var[bundle]*self.bundles_static[bundle][style+color]==self.p_ba_var[bundle,style+color]\n",
    "\n",
    "            ia_constr = []        \n",
    "            for shop in self.shops:         \n",
    "                ia_constr.append(self.p_ia_var[shop,bundle])\n",
    "            #make sure that the all distributor bundles are sent to shops\n",
    "            model += self.p_b_var[bundle]==pulp.lpSum(ia_constr)\n",
    "\n",
    "\n",
    "        #efficiency of allocation\n",
    "        allocation_eff = []\n",
    "        for shop in self.shops:\n",
    "            for style in self.styles:\n",
    "                for color in self.colors:\n",
    "                    sc_units = self.current_inventory[shop][style+color]\n",
    "                    for bundle in self.bundles:\n",
    "                        sc_units += self.p_ia_var[(shop,bundle)]*self.bundles_static[bundle][style+color] \n",
    "\n",
    "                    #allocated bundles*number of shirts in bundle_id for each style color\n",
    "                    loss = sc_units - self.desired_allocation[shop][style+color]\n",
    "                    #ensure it does not go over the desired allocation\n",
    "                    model+= loss <= 49\n",
    "                    model+= loss >= -50\n",
    "\n",
    "                    allocation_eff.append(loss)\n",
    "\n",
    "\n",
    "                    id_var_constr = []\n",
    "                    for i in range(-50,50):\n",
    "                        id_var_constr.append(self.p_id_var[(shop,style+color,i)]*i)\n",
    "\n",
    "                    model+=pulp.lpSum(id_var_constr)==loss\n",
    "\n",
    "        non_lin = [np.sqrt(i**2) for i in range(-50,50)]\n",
    "\n",
    "\n",
    "        custom_alloc_eff = []\n",
    "        i=0\n",
    "        for shop in self.shops:\n",
    "            for style in self.styles:\n",
    "                for color in self.colors:\n",
    "                    new_loss = 0\n",
    "                    for j in range(-50,50):\n",
    "                        new_loss+=self.p_id_var[(shop,style+color,j)]*non_lin[j]\n",
    "                    custom_alloc_eff.append(new_loss)\n",
    "                    i+=1\n",
    "\n",
    "        allocation_obj = pulp.lpSum(custom_alloc_eff)\n",
    "\n",
    "        model+=allocation_obj\n",
    "\n",
    "        solution = model.solve()\n",
    "\n",
    "        print(\"The Objective Value\", pulp.value(model.objective))\n",
    "        \n",
    "\n",
    "    def call(self,proba,training=False):\n",
    "        \n",
    "        next_inven = {}\n",
    "        for shop in self.shops:\n",
    "            next_inven[shop] = {}\n",
    "            for style in self.styles:\n",
    "                for color in self.colors:\n",
    "                    next_inven[shop][style+color] = self.tf_cur_inven[shop][style+color]\n",
    "                \n",
    "#         tot_proba = {}\n",
    "#         tot_bundle_alloc = {}\n",
    "#         amt_avail = {}\n",
    "\n",
    "#         for bundle in self.bundles:\n",
    "#             amt_avail[bundle] = 0\n",
    "#             tot_bundle_alloc[bundle] = 0\n",
    "#             tot_proba[bundle] = 0\n",
    "            \n",
    "#         i=0\n",
    "#         for shop in self.shops:\n",
    "#             for bundle in self.bundles:\n",
    "#                 tot_bundle_alloc[bundle] += self.tf_alloc_shp_bun[(shop,bundle)]\n",
    "#                 tot_proba[bundle] += proba[i]\n",
    "#                 i+=1   \n",
    "                \n",
    "#         for bundle in self.bundles:         \n",
    "#             amt_avail[bundle] = (self.tf_avail_bundle[bundle]-tot_bundle_alloc[bundle]-tot_proba[bundle])\n",
    "#             print('amt available')\n",
    "#             print(bundle,amt_avail[bundle].numpy(),tot_inven[bundle].numpy(),self.avail_bundle[bundle].numpy())\n",
    "            \n",
    "        new_proba = []\n",
    "        i=0\n",
    "        for shop in self.shops:\n",
    "            for bundle in self.bundles:\n",
    "#                 if amt_avail[bundle]>tot_proba[bundle] and amt_avail[bundle]>0:\n",
    "                new_proba.append([proba[i]])\n",
    "#                 if amt_avail[bundle]>0:\n",
    "#                     new_proba.append([proba[i]])\n",
    "#                 else:\n",
    "#                     new_proba.append([proba[i]*tf.cast(0.0,tf.float32)])\n",
    "                i+=1\n",
    "                \n",
    "        new_proba = tf.reshape(tf.concat(new_proba,axis=0),[-1,1])\n",
    "        \n",
    "        result_dict = {}\n",
    "        \n",
    "        i=0\n",
    "        for shop in self.shops:\n",
    "            result_dict[shop] = {}\n",
    "            for bundle in self.bundles:\n",
    "                for style in self.styles:\n",
    "                    for color in self.colors:\n",
    "                        \n",
    "                        \n",
    "                        next_inven[shop][style+color] += self.tf_bun_sty_col[bundle][style+color]*proba[i]\n",
    "                        \n",
    "                        result_dict[shop][style+color] = next_inven[shop][style+color]\n",
    "                        \n",
    "                i+=1\n",
    "\n",
    "        result = [] \n",
    "        for shop in self.shops:\n",
    "            for style in self.styles:\n",
    "                for color in self.colors:\n",
    "                    result.append([next_inven[shop][style+color]])\n",
    "                    \n",
    "        result = tf.reshape(tf.concat(result,axis=0),[1,-1])\n",
    "        \n",
    "        if training==True:\n",
    "            for shop in self.shops:\n",
    "                for style in self.styles:\n",
    "                    for color in self.colors:\n",
    "                        self.tf_cur_inven[shop][style+color] = next_inven[shop][style+color]\n",
    "            i=0\n",
    "            for shop in self.shops:\n",
    "                for bundle in self.bundles:\n",
    "                    self.tf_avail_bundle[bundle] -= proba[i]\n",
    "                    self.tf_alloc_bundle[bundle] += proba[i]\n",
    "                    self.tf_alloc_shp_bun[(shop,bundle)] += proba[i] \n",
    "                    self.tf_proba[(shop,bundle)] = proba[i]\n",
    "                    i+=1\n",
    "                    \n",
    "#             for bundle in self.bundles:\n",
    "#                 if self.tf_alloc_bundle[bundle]<0:\n",
    "#                     print(self.tf_alloc_bundle[bundle])\n",
    "#                 self.tf_avail_bundle[bundle] = tf.math.maximum(0,self.tf_avail_bundle[bundle])\n",
    "#                 self.tf_alloc_bundle[bundle] = tf.math.maximum(0,self.tf_alloc_bundle[bundle])\n",
    "                \n",
    "        return result\n",
    "    \n",
    "    def get_bun_sku(self):\n",
    "        bun_lkup = []\n",
    "        for bundle in self.bundles:\n",
    "            for style in self.styles:\n",
    "                for color in self.colors:\n",
    "                    bun_lkup.append([self.tf_bun_sty_col[bundle][style+color]])\n",
    "        bun_lkup = tf.reshape(tf.concat(bun_lkup,axis=0),[1,-1])\n",
    "        return bun_lkup\n",
    "\n",
    "    def set_bun_sku(self,x):\n",
    "        x = tf.squeeze(x)\n",
    "        i=0\n",
    "        for bundle in self.bundles:\n",
    "            for style in self.styles:\n",
    "                for color in self.colors:\n",
    "                    self.tf_bun_sty_col[bundle][style+color] = x[i]\n",
    "                    i+=1\n",
    "        return\n",
    "\n",
    "    def get_ava_bun(self):\n",
    "        ava_bun = []\n",
    "        for bundle in self.bundles:\n",
    "            ava_bun.append([self.tf_avail_bundle[bundle]])\n",
    "        ava_bun = tf.reshape(tf.concat(ava_bun,axis=0),[1,-1])\n",
    "        return ava_bun\n",
    "\n",
    "    def set_ava_bun(self,x):\n",
    "        x = tf.squeeze(x)\n",
    "        i=0\n",
    "        for bundle in self.bundles:\n",
    "            self.tf_avail_bundle[bundle] = x[i]\n",
    "            i+=1\n",
    "        return\n",
    "\n",
    "    def get_cur_inv(self):\n",
    "        cur_inventory = []\n",
    "        for shop in self.shops:\n",
    "            for style in self.styles:\n",
    "                for color in self.colors:\n",
    "                    cur_inventory.append([self.tf_cur_inven[shop][style+color]])\n",
    "        cur_inventory = tf.reshape(tf.concat(cur_inventory,axis=0),[1,-1])\n",
    "        return cur_inventory\n",
    "\n",
    "    def set_cur_inv(self,x):\n",
    "        x = tf.squeeze(x)\n",
    "        i=0\n",
    "        for shop in self.shops:\n",
    "            for style in self.styles:\n",
    "                for color in self.colors:\n",
    "                    self.tf_cur_inven[shop][style+color] = x[i]\n",
    "                    i+=1\n",
    "        return\n",
    "\n",
    "    def get_shop_bun_alloc(self):\n",
    "\n",
    "        shop_bundle_alloc = []\n",
    "        for shop in self.shops:\n",
    "            for bundle in self.bundles:\n",
    "                shop_bundle_alloc.append([self.tf_alloc_shp_bun[(shop,bundle)]])\n",
    "\n",
    "        shop_bundle_alloc = tf.reshape(tf.concat(shop_bundle_alloc,axis=0),[1,-1])\n",
    "        return shop_bundle_alloc\n",
    "\n",
    "    def set_shop_bun_alloc(self,x):\n",
    "        x = tf.squeeze(x)\n",
    "        i=0\n",
    "        for shop in self.shops:\n",
    "            for bundle in self.bundles:\n",
    "                self.tf_alloc_shp_bun[(shop,bundle)] = x[i]\n",
    "                i+=1\n",
    "        return\n",
    "\n",
    "    def get_shop_bun_proba(self):\n",
    "\n",
    "        shop_proba = []\n",
    "        for shop in self.shops:\n",
    "            for bundle in self.bundles:\n",
    "                shop_proba.append([self.tf_proba[(shop,bundle)]])\n",
    "\n",
    "        shop_proba = tf.reshape(tf.concat(shop_proba,axis=0),[1,-1])\n",
    "        return shop_proba\n",
    "\n",
    "    def set_shop_bun_proba(self,x):\n",
    "        x = tf.squeeze(x)\n",
    "        i=0\n",
    "\n",
    "        for shop in self.shops:\n",
    "            for bundle in self.bundles:\n",
    "                self.tf_proba[(shop,bundle)] = x[i]\n",
    "                i+=1\n",
    "        return\n",
    "    \n",
    "    def get_bun_map(self):\n",
    "\n",
    "        bun_map = []\n",
    "        \n",
    "        for style in self.styles:\n",
    "            for color in self.colors:\n",
    "                sc_units = 0\n",
    "                for bundle in self.bundles:\n",
    "                    sc_units+=self.tf_avail_bundle[bundle]*self.bundles_static[bundle][style+color]\n",
    "\n",
    "                bun_map.append([sc_units])\n",
    "\n",
    "        bun_map = tf.reshape(tf.concat(bun_map,axis=0),[1,-1])\n",
    "        return bun_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f02bc4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pulp\n",
    "_p_b_var = pulp.LpVariable.dicts('bundle_gather', [1],lowBound=0, cat=\"Integer\")\n",
    "\n",
    "\n",
    "_p_b_var2 = pulp.LpVariable.dicts('bundle_gather', [1,2],lowBound=0, cat=\"Integer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "798a73ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: None}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e12dafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.block.avail_bundle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b22e6938",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "\n",
    "def get_states(self):\n",
    "        bun_lkup = []\n",
    "        for bundle in self.block.bundles:\n",
    "            for style in self.block.styles:\n",
    "                for color in self.block.colors:\n",
    "                    bun_lkup.append([self.block.tf_bun_sty_col[bundle][style+color]])\n",
    "        bun_lkup = tf.reshape(tf.concat(bun_lkup,axis=0),[1,-1])\n",
    "        \n",
    "        ava_bun = []\n",
    "        alloc_bun = []\n",
    "        for bundle in self.block.bundles:\n",
    "#             assert self.block.bundle_availability[bundle]==self.block.tf_avail_bundle[bundle]+self.block.tf_alloc_bundle[bundle]\n",
    "            ava_bun.append([self.block.tf_avail_bundle[bundle]])\n",
    "        ava_bun = tf.reshape(tf.concat(ava_bun,axis=0),[1,-1])\n",
    "        \n",
    "        cur_inventory = []\n",
    "        for shop in self.block.shops:\n",
    "            for style in self.block.styles:\n",
    "                for color in self.block.colors:\n",
    "                    cur_inventory.append([self.block.tf_cur_inven[shop][style+color]])\n",
    "        cur_inventory = tf.reshape(tf.concat(cur_inventory,axis=0),[1,-1])\n",
    "        \n",
    "        shop_bundle_alloc = []\n",
    "        shop_proba = []\n",
    "        for shop in self.block.shops:\n",
    "            for bundle in self.block.bundles:\n",
    "                shop_proba.append([self.block.tf_proba[(shop,bundle)]])\n",
    "                shop_bundle_alloc.append([self.block.tf_alloc_shp_bun[(shop,bundle)]])\n",
    "                \n",
    "        shop_proba = tf.reshape(tf.concat(shop_proba,axis=0),[1,-1])\n",
    "        shop_bundle_alloc = tf.reshape(tf.concat(shop_bundle_alloc,axis=0),[1,-1])\n",
    "        \n",
    "        return bun_lkup,ava_bun, cur_inventory, shop_bundle_alloc, shop_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5562e658",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def sumOfSquareErrors(ytrue,ypred):\n",
    "    \n",
    "    loss = tf.reduce_sum(tf.square(ypred - ytrue))\n",
    "    return loss\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def rewardFunction(ytrue,ypred,ylimit):\n",
    "    \n",
    "    limit = tf.reshape(tf.cast(tf.reduce_sum(ypred,axis=0)-ylimit>0,tf.float32),[1,-1])\n",
    "    \n",
    "    penalty = tf.cast(ypred<0, tf.float32)\n",
    "    \n",
    "    pos_reward = tf.clip_by_value(ytrue - ypred,0,1e4)\n",
    "\n",
    "    neg_reward = tf.clip_by_value(ytrue - ypred,-1e4,0)\n",
    "    \n",
    "    ypred_shifted = ypred-tf.math.reduce_min(ypred)\n",
    "    shape_reward = ytrue - tf.reduce_sum(ytrue)*(ypred_shifted)/tf.reduce_sum(ypred_shifted) \n",
    "    \n",
    "    reward = pos_reward+0.1*pos_reward*penalty+0.5*neg_reward - 10*limit + 0.01*shape_reward\n",
    "    \n",
    "    return tf.reshape(reward,[1,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7fe7bd2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MIP_NN():\n",
    "    \n",
    "    def __init__(self,\n",
    "                   alpha=0.95):\n",
    "        \n",
    "        self.vid_count=0\n",
    "        self.gamma = 1e-1\n",
    "        self.alpha = alpha\n",
    "        \n",
    "        self.optimizer = tf.keras.optimizers.Adam(learning_rate=0.000001)\n",
    "        self.loss_function = sumOfSquareErrors\n",
    "        self.init_block()\n",
    "\n",
    "        self.model = self.create_model()\n",
    "        self.prev_loss = 1e6\n",
    "        \n",
    "#         self.model = tf.keras.Sequential([DensityBlock(self._bins_,\n",
    "#                                                        self.means,\n",
    "#                                                        self.devs,\n",
    "#                                                        self.maxs,\n",
    "#                                                        self.mins,\n",
    "#                                                        self.widths)])\n",
    "        \n",
    "#         self.model.compile(optimizer='adam',loss=sumOfSquareErrors,learning_rate=0.001)\n",
    "\n",
    "    def init_block(self,use_mip_solver=True,seed=1,shuffle_bundles=False):\n",
    "        self.prev_loss = 1e6\n",
    "        self.block = OptBlock(seed=seed,use_mip_solver=use_mip_solver,shuffle_bundles=shuffle_bundles)\n",
    "        \n",
    "    def create_model(self):\n",
    "            \n",
    "        bun_lkup = self.block.get_bun_sku()\n",
    "        ava_bun = self.block.get_ava_bun()\n",
    "        cur_inventory = self.block.get_cur_inv()\n",
    "        shop_bundle_alloc = self.block.get_shop_bun_alloc()\n",
    "        shop_bun_proba = self.block.get_shop_bun_proba()\n",
    "            \n",
    "        in_bun_lkup = tf.keras.Input(shape=bun_lkup.shape[1])\n",
    "        in_ava_bund = tf.keras.Input(shape=ava_bun.shape[1])\n",
    "        in_cur_inven = tf.keras.Input(shape=cur_inventory.shape[1])\n",
    "        in_shop_bun = tf.keras.Input(shape=shop_bundle_alloc.shape[1])\n",
    "        in_shop_bun_prob = tf.keras.Input(shape=shop_bun_proba.shape[1])\n",
    "        \n",
    "        \n",
    "#         tmp = tf.reshape(in_cur_inven,[1,len(self.block.shops),len(self.block.styles)*len(self.block.colors)])\n",
    "#         tmp = tf.transpose(tmp,perm=[0,2,1])\n",
    "#         tmp = tmp*in_ava_bund\n",
    "#         print(tmp.shape)\n",
    "#         tmp = tf.keras.layers.Flatten()(tmp)\n",
    "        \n",
    "        N_shops = len(self.block.shops)\n",
    "        N_bundles = len(self.block.bundles)\n",
    "        N_style_clors = len(self.block.styles)*len(self.block.colors)\n",
    "    \n",
    "        remain_sc = tf.reshape(in_bun_lkup,[1,N_bundles,N_style_clors])\n",
    "        remain_sc = tf.transpose(remain_sc,perm=[0,2,1])\n",
    "        remain_sc = remain_sc*in_ava_bund\n",
    "        remain_sc = tf.keras.layers.Flatten()(remain_sc)\n",
    "        \n",
    "        prev_shop_bund = in_shop_bun-in_shop_bun_prob\n",
    "        \n",
    "        x_shop_bun = tf.keras.layers.Concatenate()([in_ava_bund,in_shop_bun,prev_shop_bund])\n",
    "        x_shop_bun = tf.keras.layers.Dense(N_shops*N_shops*N_bundles*N_bundles, activation=\"linear\",use_bias=True)(x_shop_bun)\n",
    "        \n",
    "        x_style_co = tf.keras.layers.Concatenate()([in_cur_inven,remain_sc])\n",
    "        x_style_co = tf.keras.layers.Dense(N_shops*N_shops*N_style_clors*N_style_clors, activation=\"linear\",use_bias=True)(x_style_co)\n",
    "        \n",
    "        #available bundles, allocated shop_bundles, prev_shop_bund\n",
    "        #allocated shop_style_colors, remaining style_colors\n",
    "        #available style_colors\n",
    "                              \n",
    "        \n",
    "        out_shape = shop_bun_proba.shape[1]\n",
    "        \n",
    "        x = tf.keras.layers.Concatenate()([x_shop_bun,x_style_co,in_shop_bun_prob])\n",
    "        x = tf.keras.layers.Dense(N_shops*N_shops*N_bundles*N_bundles*N_style_clors, activation=\"linear\",use_bias=True)(x)\n",
    "        x = tf.keras.layers.Dense(N_shops*N_shops*N_bundles*N_bundles*N_style_clors, activation=\"linear\",use_bias=True)(x)\n",
    "        \n",
    "        scale = 10.0\n",
    "        lower = 5.0\n",
    "        output = scale * tf.keras.layers.Dense(out_shape, activation=\"sigmoid\",use_bias=True)(x) - lower\n",
    "        \n",
    "        inputs=[in_bun_lkup,in_ava_bund,in_cur_inven,in_shop_bun,in_shop_bun_prob]\n",
    "        model = tf.keras.Model(inputs, output)\n",
    "        return model\n",
    "    \n",
    "\n",
    "    def batch_train(self,move_num=0):\n",
    "        #get the current state\n",
    "        \n",
    "        \n",
    "        z_bun_lkup_backup = self.block.get_bun_sku()\n",
    "        z_ava_bun_backup = self.block.get_ava_bun()\n",
    "        z_cur_inventory_backup = self.block.get_cur_inv()\n",
    "        z_shop_bundle_alloc_backup = self.block.get_shop_bun_alloc()\n",
    "        z_proba_backup = self.block.get_shop_bun_proba()\n",
    "        \n",
    "#         if tf.reduce_sum(tf.cast(z_ava_bun_backup<-3,tf.float32)):\n",
    "#             print('stopping, no available bundles')\n",
    "#             return 0\n",
    "        \n",
    "\n",
    "#         if tf.reduce_sum(tf.cast(z_cur_inventory_backup<-3,tf.float32)):\n",
    "#             print('stopping, negative inventory')\n",
    "#             return 0\n",
    "        \n",
    "        \n",
    "        N_moves_left = 10\n",
    "        \n",
    "        for i in range(N_moves_left):\n",
    "            \n",
    "            z_bun_lkup = self.block.get_bun_sku()\n",
    "            z_ava_bun = self.block.get_ava_bun()\n",
    "            z_cur_inventory = self.block.get_cur_inv()\n",
    "            z_shop_bundle_alloc = self.block.get_shop_bun_alloc()\n",
    "            z_proba = self.block.get_shop_bun_proba()\n",
    "            z_bun_map = self.block.get_bun_map()\n",
    "            \n",
    "            #caculate the next state without training model\n",
    "            proba_update = self.model([tf.cast(z_bun_lkup,tf.float32),\n",
    "                                                 tf.cast(z_ava_bun,tf.float32),\n",
    "                                                 tf.cast(z_cur_inventory,tf.float32),\n",
    "                                                 tf.cast(z_shop_bundle_alloc,tf.float32),\n",
    "                                                 tf.cast(z_proba,tf.float32)],training=False)\n",
    "\n",
    "            proba_update=tf.squeeze(proba_update)\n",
    "\n",
    "#             proba_update=tf.clip_by_value(tf.squeeze(proba_update),-1.,1.)\n",
    "#             proba_update=tf.squeeze(proba_update)\n",
    "#             print(proba_update.numpy())\n",
    "            q_proba=tf.squeeze(z_proba)+self.gamma*proba_update\n",
    "    \n",
    "#             q_proba=tf.clip_by_value(tf.squeeze(z_proba)+self.gamma*proba_update,-1.,1.)\n",
    "#             print(q_proba.numpy())\n",
    "            #state update\n",
    "            cur_inventory = self.block.call(q_proba,training=True)\n",
    "\n",
    "            #calculate expected reward\n",
    "            \n",
    "            \n",
    "            rs_bun = tf.reshape(z_bun_map,[1,len(self.block.styles)*len(self.block.colors)])\n",
    "            \n",
    "            rs_target = tf.reshape(self.block.target,[len(self.block.shops),len(self.block.styles)*len(self.block.colors)])\n",
    "            \n",
    "            rs_ci = tf.reshape(cur_inventory,[len(self.block.shops),len(self.block.styles)*len(self.block.colors)])\n",
    "            \n",
    "\n",
    "            if i==0:\n",
    "                q_reward = rewardFunction(rs_target,rs_ci,rs_bun)\n",
    "            elif i>0:\n",
    "                q_reward = self.alpha*q_reward + (1-self.alpha)*rewardFunction(rs_target,rs_ci,rs_bun)\n",
    "                \n",
    "                \n",
    "\n",
    "#         if self.prev_loss<tf.reduce_mean(tf.math.abs(q_reward)).numpy():\n",
    "#             print('stop reward')\n",
    "#             return 0\n",
    "        \n",
    "        self.prev_loss = tf.reduce_mean(tf.math.abs(q_reward)).numpy()\n",
    "                \n",
    "        q_cur_inventory = q_reward+z_cur_inventory_backup\n",
    "#         self.block.set_bun_sku(z_bun_lkup_backup)\n",
    "        self.block.set_ava_bun(z_ava_bun_backup)\n",
    "        self.block.set_cur_inv(z_cur_inventory_backup)\n",
    "        self.block.set_shop_bun_alloc(z_shop_bundle_alloc_backup)\n",
    "        self.block.set_shop_bun_proba(z_proba_backup)\n",
    "        \n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            #train model and get next state q_value\n",
    "            proba_update = self.model([tf.cast(z_bun_lkup_backup,tf.float32),\n",
    "                                                 tf.cast(z_ava_bun_backup,tf.float32),\n",
    "                                                 tf.cast(z_cur_inventory_backup,tf.float32),\n",
    "                                                 tf.cast(z_shop_bundle_alloc_backup,tf.float32),\n",
    "                                                 tf.cast(z_proba_backup,tf.float32)],training=True)\n",
    "            \n",
    "#             proba_update=tf.clip_by_value(tf.squeeze(proba_update),-1.,1.)\n",
    "            proba_update=tf.squeeze(proba_update)\n",
    "\n",
    "            q_proba=tf.squeeze(z_proba_backup)+self.gamma*proba_update\n",
    "            \n",
    "#             q_proba=tf.clip_by_value(tf.squeeze(z_proba_backup)+self.gamma*proba_update,-1.,1.)\n",
    "            print(q_proba)\n",
    "            cur_inventory = self.block.call(q_proba,training=True)\n",
    "#             cur_inventory = tf.cast(cur_inventory,tf.float32)\n",
    "\n",
    "#             z_bun_lkup_backup,z_ava_bun_backup,z_cur_inventory_backup,z_proba_backup = self.get_states()\n",
    "\n",
    "\n",
    "#             if tf.reduce_sum(tf.cast(z_ava_bun_backup<-3,tf.float32)):\n",
    "#                 print('stopping, no available bundles')\n",
    "#                 return 0\n",
    "\n",
    "\n",
    "#             if tf.reduce_sum(tf.cast(z_cur_inventory_backup<-3,tf.float32)):\n",
    "#                 print('stopping, negative inventory')\n",
    "#                 return 0\n",
    "            \n",
    "\n",
    "        \n",
    "            #add reward to q_function\n",
    "            \n",
    "\n",
    "            loss = self.loss_function(q_cur_inventory,cur_inventory)\n",
    "            grads = tape.gradient(loss, self.model.trainable_variables)\n",
    "            \n",
    "            print('loss',loss.numpy(),'reward',tf.reduce_mean(tf.math.abs(q_reward)).numpy())\n",
    "            self.optimizer.apply_gradients(zip(grads, self.model.trainable_variables))\n",
    "#             self.gamma-=1e-4\n",
    "            \n",
    "#             if tf.reduce_mean(tf.math.abs(q_reward)).numpy()<5:\n",
    "#                 return 0\n",
    "            \n",
    "            if tf.reduce_mean(tf.math.abs(q_reward)).numpy()<10:\n",
    "                plt.figure(figsize=(15,10))\n",
    "                matrows=1\n",
    "                pltrows=1\n",
    "\n",
    "                cnt=0\n",
    "                plt.subplot(matrows, 4, pltrows).set_axis_off()\n",
    "                pltrows+=1\n",
    "                if cnt==0:\n",
    "                    plt.title('Reward',fontsize=16)\n",
    "                plt.imshow(q_reward.numpy().reshape(-1,3))\n",
    "                plt.subplot(matrows, 4, pltrows).set_axis_off()\n",
    "                pltrows+=1\n",
    "                if cnt==0:\n",
    "                    plt.title('Q-Function',fontsize=16)\n",
    "                plt.imshow(cur_inventory.numpy().reshape(-1,3))\n",
    "                plt.subplot(matrows, 4, pltrows).set_axis_off()\n",
    "                pltrows+=1\n",
    "                if cnt==0:\n",
    "                    plt.title('Target',fontsize=16)\n",
    "                plt.imshow(self.block.target.numpy().reshape(-1,3))\n",
    "                plt.subplot(matrows, 4, pltrows).set_axis_off()\n",
    "                pltrows+=1\n",
    "                if cnt==0:\n",
    "                    plt.title('Updated Q-Function',fontsize=16)\n",
    "                plt.imshow(q_cur_inventory.numpy().reshape(-1,3))\n",
    "\n",
    "                plt.tick_params(\n",
    "                    axis='both',          # changes apply to the x-axis\n",
    "                    which='both',      # both major and minor ticks are affected\n",
    "                    bottom=False,      # ticks along the bottom edge are off\n",
    "                    top=False,         # ticks along the top edge are off\n",
    "                    left=False,\n",
    "                    labelleft=False,\n",
    "                    labelbottom=False) # labels along the bottom edge are off\n",
    "\n",
    "                plt.subplots_adjust(wspace=0, hspace=0.1)\n",
    "                folder='video'\n",
    "    #             plt.savefig(folder + \"/file%02d.png\" % self.vid_count)\n",
    "    #             if np.random.uniform()>0.9:\n",
    "                plt.show()\n",
    "                plt.close()\n",
    "                self.vid_count+=1\n",
    "            \n",
    "            return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3eb013",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a25f5cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.block.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0501e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4e85bc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.block.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "92952a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.model.trainable_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "231e5b89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rohan\\Anaconda3\\envs\\datasci\\lib\\site-packages\\pulp\\pulp.py:1704: UserWarning: Overwriting previously set objective.\n",
      "  warnings.warn(\"Overwriting previously set objective.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Objective Value 1117.0\n"
     ]
    }
   ],
   "source": [
    "model = MIP_NN(alpha=0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "72110407",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for _ in range(10):\n",
    "#     for i in range(5):\n",
    "#         model.init_block(seed=i) \n",
    "#     #     model.run_mip()\n",
    "#     #     model.create_tf_vars()\n",
    "#         for _ in range(10):\n",
    "#             model.batch_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd7f1cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Objective Value 1054.0\n",
      "tf.Tensor(\n",
      "[-0.3449938  -0.49819818 -0.28666124 -0.26254737  0.48168182  0.4273034\n",
      " -0.4934793   0.4892439   0.06072736  0.36878482  0.06888027 -0.4852909\n",
      " -0.21338964 -0.39768454 -0.35138285  0.31819925 -0.33993146 -0.49888465\n",
      " -0.3994182  -0.49905688  0.12388372 -0.39409873  0.3737011   0.17971043\n",
      " -0.36054736  0.4591465   0.40277797 -0.4070166  -0.39025414  0.09378939\n",
      " -0.20578015  0.2278719   0.3775835   0.27746364 -0.06416469  0.312564\n",
      " -0.43622217  0.05889263 -0.49507037], shape=(39,), dtype=float32)\n",
      "loss 26184.266 reward 28.00042\n",
      "tf.Tensor(\n",
      "[-0.5168788  -0.99664664 -0.46648824 -0.36527634  0.96488094  0.8828589\n",
      " -0.9859272   0.98040056  0.30363554  0.8306737   0.46787947 -0.968276\n",
      " -0.25121546 -0.69181496 -0.61829054  0.71212184 -0.59825814 -0.99739265\n",
      " -0.76270205 -0.9980252   0.42580023 -0.7656512   0.7640244   0.5552943\n",
      " -0.6327108   0.92254716  0.8743366  -0.77455175 -0.7245289   0.29387698\n",
      " -0.22486517  0.6388427   0.7753736   0.6706339   0.01577076  0.7632829\n",
      " -0.8449352   0.3107375  -0.9882561 ], shape=(39,), dtype=float32)\n",
      "loss 23499.924 reward 26.432837\n",
      "tf.Tensor(\n",
      "[-0.38296902 -1.4954045  -0.49339515 -0.24288282  1.4473199   1.3494973\n",
      " -1.4774355   1.4728514   0.6546234   1.3117926   0.9261199  -1.4490204\n",
      " -0.1168015  -0.6825683  -0.6791331   1.1446059  -0.7011144  -1.4942528\n",
      " -1.1141634  -1.4968882   0.8294654  -1.1013682   1.1528482   1.0046564\n",
      " -0.70426184  1.3745378   1.3618819  -1.0518234  -0.92033297  0.5239794\n",
      " -0.00361091  1.1099054   1.1852239   1.1180589   0.19278093  1.2384869\n",
      " -1.2276013   0.7009082  -1.4730542 ], shape=(39,), dtype=float32)\n",
      "loss 20913.824 reward 24.312431\n",
      "tf.Tensor(\n",
      "[-0.09542134 -1.9944197  -0.34304124  0.03499356  1.9225504   1.8141125\n",
      " -1.9678936   1.9662751   1.0479636   1.7990646   1.3861284  -1.928044\n",
      "  0.10449409 -0.3100965  -0.45028067  1.5945381  -0.58926684 -1.9821492\n",
      " -1.4941765  -1.9954889   1.2765749  -1.3771068   1.5314157   1.4767978\n",
      " -0.5304738   1.7791115   1.8529669  -1.1124467  -0.8247632   0.7116974\n",
      "  0.3655387   1.5986009   1.5941639   1.5946788   0.37698388  1.7158237\n",
      " -1.6003392   1.1528744  -1.9136486 ], shape=(39,), dtype=float32)\n",
      "loss 18586.516 reward 22.15169\n",
      "tf.Tensor(\n",
      "[ 0.14629161 -2.4936106  -0.02937564  0.37166807  2.3677502   2.25383\n",
      " -2.4561172   2.4608288   1.4378512   2.2879918   1.7946935  -2.4073758\n",
      "  0.33769017  0.1645928  -0.03926009  2.050986   -0.28417823 -2.3938344\n",
      " -1.9210253  -2.4934444   1.7407213  -1.5365524   1.8994428   1.9518741\n",
      " -0.19865924  2.0301123   2.3404968  -0.83818424 -0.43721434  0.7696025\n",
      "  0.79473114  2.0921965   1.9859507   2.0861297   0.45287386  2.1785855\n",
      " -1.9871371   1.627952   -2.0769637 ], shape=(39,), dtype=float32)\n",
      "loss 19477.973 reward 18.96296\n",
      "tf.Tensor(\n",
      "[ 0.06320474 -2.9929252   0.38356525  0.69689715  2.662012    2.586807\n",
      " -2.9389393   2.9570093   1.7647054   2.7751303   1.8969939  -2.8898323\n",
      "  0.4982732   0.65769446  0.43165523  2.5058358   0.12689212 -2.2400043\n",
      " -2.3893225  -2.9899945   2.2101274  -1.4813806   2.2249682   2.411327\n",
      "  0.18799773  1.9743184   2.8050597  -0.38424107  0.04351878  0.5898315\n",
      "  1.242063    2.5863755   2.3371167   2.5836544   0.25592497  2.5632594\n",
      " -2.42136     2.1114953  -1.6836854 ], shape=(39,), dtype=float32)\n",
      "loss 25408.137 reward 20.369078\n",
      "tf.Tensor(\n",
      "[-0.38144243 -3.492374    0.8421432   0.95097184  2.4039748   2.5323608\n",
      " -3.4087355   3.4549892   1.9418733   3.255206    1.4644386  -3.376497\n",
      "  0.46731496  1.1546597   0.9200866   2.9449327   0.5815898  -1.7477808\n",
      " -2.8808668  -3.4836073   2.6762211  -1.1687402   2.3749745   2.796599\n",
      "  0.5663937   1.6464325   3.1302116   0.10871422  0.5404825   0.19111356\n",
      "  1.6844567   3.077647    2.603714    3.0830476  -0.17935097  2.5307975\n",
      " -2.9027848   2.5980487  -1.1886119 ], shape=(39,), dtype=float32)\n",
      "loss 35832.25 reward 21.603579\n",
      "tf.Tensor(\n",
      "[-0.8799278  -3.9920418   1.3188843   1.0516856   1.9133145   2.0868251\n",
      " -3.8473432   3.9542499   1.8987508   3.7132947   0.9662195  -3.8674157\n",
      "  0.1580973   1.6527275   1.4144771   3.3431475   1.053114   -1.2478716\n",
      " -3.3794398  -3.9713955   3.1291811  -0.71490216  2.0385826   2.845455\n",
      "  0.8589755   1.1948851   2.87574     0.6075729   1.0399318  -0.28982922\n",
      "  2.0880344   3.5572495   2.6684954   3.582913   -0.670376    2.0495758\n",
      " -3.4002564   3.0848367  -0.68880033], shape=(39,), dtype=float32)\n",
      "loss 48554.69 reward 25.602957\n",
      "tf.Tensor(\n",
      "[-1.3799018  -4.4919243   1.8021681   0.97784626  1.4135206   1.5901738\n",
      " -4.1987004   4.4540615   1.6734598   4.0877795   0.4662552  -4.361638\n",
      " -0.30245513  2.1514366   1.9115144   3.6639383   1.5359246  -0.74787295\n",
      " -3.879225   -4.4526505   3.564879   -0.22268167  1.5450792   2.3744957\n",
      "  0.9323184   0.7098141   2.38276     1.1073277   1.5397942  -0.7868907\n",
      "  2.3433557   3.985412    2.3440766   4.082886   -1.1690148   1.5499005\n",
      " -3.899996    3.571958   -0.18880883], shape=(39,), dtype=float32)\n",
      "loss 65256.062 reward 30.571821\n",
      "tf.Tensor(\n",
      "[-1.8799014  -4.9919033   2.2849634   0.8781966   0.91352427  1.090375\n",
      " -4.1914864   4.954029    1.3539339   3.8881793  -0.03374416 -4.857979\n",
      " -0.7976178   2.650707    2.4099805   3.8354967   2.0274513  -0.24787295\n",
      " -4.379188   -4.932939    3.9705625   0.2763248   1.0452604   1.8750196\n",
      "  0.69932723  0.21584362  1.8829136   1.607254    2.0397413  -1.286401\n",
      "  2.0062175   3.886145    1.855432    4.5828815  -1.6687291   1.0499066\n",
      " -4.399969    4.0606084   0.3111907 ], shape=(39,), dtype=float32)\n",
      "loss 83206.836 reward 35.835873\n",
      "tf.Tensor(\n",
      "[-2.3799014  -5.4919014   2.7580118   0.9000149   0.41352436  0.59039307\n",
      " -3.7383847   5.454025    0.99476945  3.393849   -0.53374416 -5.35596\n",
      " -1.2972747   3.150394    2.909246    3.7770264   2.5238905   0.25212705\n",
      " -4.879178   -5.416915    4.317938    0.7762104   0.5452687   1.3750342\n",
      "  0.29784736 -0.28068835  1.3829191   2.1072228   2.539707   -1.7862946\n",
      "  1.5126851   3.3866658   1.3562431   5.0828805  -2.1685972   0.54990685\n",
      " -4.899966    4.551929    0.8111907 ], shape=(39,), dtype=float32)\n",
      "loss 104746.12 reward 41.57822\n",
      "tf.Tensor(\n",
      "[-2.8799014  -5.9919014   3.1873636   1.3361737  -0.08647564  0.09039548\n",
      " -3.2391493   5.9540243   0.7102829   2.8939059  -1.0337441  -5.854977\n",
      " -1.7972546   3.6502938   3.4089346   3.409974    3.0225883   0.75212705\n",
      " -5.379173   -5.906586    4.3453116   1.2761984   0.04526913  0.8750347\n",
      " -0.15349266 -0.77728605  0.88291943  2.607203    3.0396707  -2.286261\n",
      "  1.0128326   2.886666    0.85629773  5.5828805  -2.6684637   0.04990685\n",
      " -5.3999653   5.045839    1.3111907 ], shape=(39,), dtype=float32)\n",
      "loss 130908.36 reward 47.34575\n",
      "tf.Tensor(\n",
      "[-3.3799014  -6.4919014   3.4291964   1.8343661  -0.5864756  -0.40960404\n",
      " -2.7391565   6.4540243   0.8695979   2.3939066  -1.5337441  -6.354548\n",
      " -2.2972536   4.150271    3.9088142   2.931559    3.522171    1.252127\n",
      " -5.879167   -6.401523    3.8650224   1.7761973  -0.45473084  0.3750347\n",
      " -0.61556524 -1.2714425   0.38291946  3.107184    3.5396087  -2.7862458\n",
      "  0.5128354   2.386666    0.35630146  6.0828805  -3.1681921  -0.45009315\n",
      " -5.8999653   5.5421357   1.8111907 ], shape=(39,), dtype=float32)\n",
      "loss 164702.81 reward 53.32294\n",
      "tf.Tensor(\n",
      "[-3.8799014  -6.9919014   3.3421679   2.334331   -1.0864756  -0.9096039\n",
      " -2.2391565   6.9540243   1.3665432   1.8939066  -2.033744   -6.8543735\n",
      " -2.7972536   4.650267    4.408772    2.4349263   4.022057    1.752127\n",
      " -6.3791537  -6.8996253   3.3653505   2.2761974  -0.95473087 -0.12496531\n",
      " -1.0597547  -1.7538246  -0.11708054  3.607154    4.0394354  -3.2862365\n",
      "  0.01283541  1.886666   -0.14369828  6.5828805  -3.6671915  -0.95009315\n",
      " -6.3999653   6.0401564   2.3111906 ], shape=(39,), dtype=float32)\n",
      "loss 206814.97 reward 60.993317\n",
      "tf.Tensor(\n",
      "[-4.3799014  -7.4919014   3.4146986   2.8343306  -1.5864756  -1.4096038\n",
      " -1.7391565   7.4540243   1.8665326   1.3939066  -2.533744   -7.3543096\n",
      " -3.2972536   5.1502666   4.908758    1.9355452   4.522033    2.2521272\n",
      " -6.879078   -7.3990264   2.8653564   2.7761974  -1.4547309  -0.6249653\n",
      " -1.3316842  -2.1520193  -0.61708057  4.107079    4.5386457  -3.786229\n",
      " -0.4871646   1.386666   -0.6436982   7.0828805  -4.160829   -1.4500932\n",
      " -6.8999653   6.5392027   2.8111906 ], shape=(39,), dtype=float32)\n",
      "loss 261952.86 reward 70.89529\n",
      "tf.Tensor(\n",
      "[-4.8799014  -7.9919014   3.9002862   3.3343306  -2.0864756  -1.9096038\n",
      " -1.2391565   7.9540243   2.3665326   0.8939066  -3.033744   -7.8542886\n",
      " -3.7972536   5.6502666   5.4087543   1.435714    5.0220294   2.7521272\n",
      " -7.3779097  -7.8988624   2.3653567   3.2761974  -1.9547309  -1.1249653\n",
      " -0.8447645  -1.9306712  -1.1170806   4.6067867   5.033471   -4.28622\n",
      " -0.9871646   0.88666606 -1.1436982   7.5828805  -4.596302   -1.9500932\n",
      " -7.3999653   7.0388074   3.3111906 ], shape=(39,), dtype=float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 331378.47 reward 81.76984\n",
      "tf.Tensor(\n",
      "[-5.3799014  -8.491901    4.4001045   3.8343306  -2.5864756  -2.4096038\n",
      " -0.7391565   8.454024    2.8665326   0.3939066  -3.533744   -8.354283\n",
      " -4.2972536   6.1502666   5.9087534   0.9357828   5.522029    3.2521272\n",
      " -7.8204374  -8.3988285   1.8653567   3.7761974  -2.454731   -1.6249653\n",
      " -0.3447823  -1.4311193  -1.6170806   5.105016    5.4878254  -4.786205\n",
      " -1.4871646   0.38666606 -1.6436982   8.08288    -4.6225877  -2.4500933\n",
      " -7.8999653   7.5386624   3.8111906 ], shape=(39,), dtype=float32)\n",
      "loss 424136.53 reward 93.92124\n",
      "tf.Tensor(\n",
      "[-5.879901   -8.991901    4.900099    4.3343306  -3.0864756  -2.9096038\n",
      " -0.23915648  8.954024    3.3665326  -0.10609341 -4.033744   -8.854282\n",
      " -4.7972536   6.6502666   6.408753    0.4358266   6.022029    3.7521272\n",
      " -7.3204465  -8.898824    1.3653567   4.2761974  -2.954731   -2.1249652\n",
      "  0.1552177  -0.9311197  -2.1170805   5.589122    5.5325766  -5.286165\n",
      " -1.9871646  -0.11333394 -2.1436982   8.58288    -4.172224   -2.9500933\n",
      " -8.399965    8.038608    4.3111887 ], shape=(39,), dtype=float32)\n",
      "loss 529760.9 reward 106.024124\n",
      "tf.Tensor(\n",
      "[-6.379847   -9.491901    5.400099    4.8343306  -3.5864756  -3.4096038\n",
      "  0.26084352  9.454024    3.8665326  -0.6060934  -4.533744   -9.354282\n",
      " -5.2972536   7.1502666   6.908753   -0.06413236  6.522029    4.252127\n",
      " -6.8204465  -9.398823    0.8653567   4.7761974  -3.454731   -2.6249652\n",
      "  0.6552177  -0.43111968 -2.6170793   5.7173605   5.0398555  -5.786006\n",
      " -2.4871645  -0.61333394 -2.6436982   9.08288    -3.6735258  -3.450093\n",
      " -8.899965    8.538585    4.8111324 ], shape=(39,), dtype=float32)\n",
      "loss 662913.75 reward 118.177475\n",
      "tf.Tensor(\n",
      "[-6.8537693  -9.991901    5.900099    5.3343306  -4.0864754  -3.9096038\n",
      "  0.7608435   9.954024    4.3665323  -1.1060934  -5.033744   -9.854282\n",
      " -5.7972536   7.6502666   7.408753   -0.56406736  7.022029    4.752127\n",
      " -6.3204465  -9.898823    0.36535668  5.2761974  -3.954731   -3.1249652\n",
      "  1.1552176   0.06888032 -3.1170542   5.2173605   4.5399327  -6.2849135\n",
      " -2.9871645  -1.113334   -3.1436982   9.58288    -3.1735473  -3.9500892\n",
      " -9.399965    9.038574    5.307444  ], shape=(39,), dtype=float32)\n",
      "loss 817320.7 reward 130.80313\n",
      "The Objective Value 1126.0\n",
      "tf.Tensor(\n",
      "[ 0.46330205 -0.45572096  0.3657011  -0.30096027  0.09719973  0.0969739\n",
      " -0.49678904  0.49331972  0.3412629   0.49094144  0.1058588  -0.2665983\n",
      " -0.2504995  -0.2578741   0.48478547 -0.11899018  0.3000395  -0.09511709\n",
      " -0.38902143 -0.3128204   0.3521782   0.49879143  0.45068684 -0.06306525\n",
      "  0.10842419  0.33024988  0.4943346  -0.08690687  0.4781928   0.4374729\n",
      " -0.49460712  0.39148733  0.24649154  0.48865357  0.44625646  0.4930029\n",
      " -0.1382894  -0.053408   -0.13096678], shape=(39,), dtype=float32)\n",
      "loss 20868.357 reward 25.429373\n",
      "tf.Tensor(\n",
      "[ 0.92603046 -0.91207254  0.7638359  -0.55869764  0.09000102  0.16860199\n",
      " -0.9937798   0.98644316  0.709737    0.97859883  0.24844722 -0.52824736\n",
      " -0.5041945  -0.5115074   0.97058916 -0.24971576  0.607826   -0.16887923\n",
      " -0.7386146  -0.62280536  0.70233613  0.9971492   0.88183737 -0.19346376\n",
      "  0.21465969  0.67494535  0.9879943  -0.10562244  0.9566654   0.8796813\n",
      " -0.9902344   0.76128495  0.4509813   0.97858286  0.8852987   0.9851725\n",
      " -0.2605304  -0.07338162 -0.17784646], shape=(39,), dtype=float32)\n",
      "loss 20798.025 reward 25.220068\n",
      "tf.Tensor(\n",
      "[ 1.386903   -1.3731507   1.2098745  -0.72560716 -0.09973769  0.18458728\n",
      " -1.490751    1.4786462   1.1244575   1.453772    0.421063   -0.7850019\n",
      " -0.7656773  -0.7490834   1.4583904  -0.4121042   0.9097326  -0.22120443\n",
      " -0.981628   -0.92344975  1.0366027   1.4941877   1.2534051  -0.4734761\n",
      "  0.30785078  1.0480464   1.479948   -0.01993237  1.4350541   1.3247621\n",
      " -1.4874052   1.0546577   0.55208117  1.4705614   1.3153253   1.4754136\n",
      " -0.37972617 -0.04657169 -0.0708451 ], shape=(39,), dtype=float32)\n",
      "loss 20724.621 reward 24.476242\n",
      "tf.Tensor(\n",
      "[ 1.8480315  -1.844206    1.6913776  -0.73323566 -0.4678946   0.10293087\n",
      " -1.9874191   1.9686099   1.583172    1.8789897   0.5856324  -1.0407621\n",
      " -1.0503821  -0.964653    1.9490378  -0.6207876   1.1860511  -0.25621587\n",
      " -0.96592647 -1.2178954   1.3312953   1.9870958   1.4566258  -0.8966296\n",
      "  0.37801108  1.4620631   1.968267    0.15661669  1.9112353   1.7718232\n",
      " -1.9858968   1.15078     0.46821877  1.9645407   1.7363049   1.9618715\n",
      " -0.5458188   0.02649889  0.20679438], shape=(39,), dtype=float32)\n",
      "loss 22542.023 reward 23.438963\n",
      "tf.Tensor(\n",
      "[ 2.3140922  -2.3279653   2.1873922  -0.5284516  -0.92988014 -0.10008851\n",
      " -2.4834669   2.4531677   2.0691974   2.0945396   0.67785025 -1.2971259\n",
      " -1.3866084  -1.1619034   2.4426403  -0.8774619   1.4114612  -0.28157994\n",
      " -0.6088573  -1.5169213   1.5483013   2.4643345   1.3357877  -1.3821158\n",
      "  0.42076287  1.9184312   2.4496894   0.3825413   2.3793182   2.221429\n",
      " -2.48521     0.91806567  0.16673526  2.4600842   2.153216    2.441139\n",
      " -0.82121164  0.13188353  0.6009745 ], shape=(39,), dtype=float32)\n",
      "loss 27436.045 reward 21.581753\n",
      "tf.Tensor(\n",
      "[ 2.7896242  -2.8216615   2.6868248  -0.14564636 -1.4211664  -0.4017976\n",
      " -2.9787185   2.9226446   2.5660846   1.8612459   0.6214047  -1.5385616\n",
      " -1.7975327  -1.3513997   2.938531   -1.1689353   1.5631193  -0.30463764\n",
      " -0.12393144 -1.8313018   1.6380783   2.8695676   0.9529674  -1.8804684\n",
      "  0.4462143   2.40338     2.9204059   0.6098901   2.8213892   2.6750827\n",
      " -2.9849336   0.47259548 -0.27253497  2.9568055   2.578867    2.9069378\n",
      " -1.22042     0.24513933  1.0488647 ], shape=(39,), dtype=float32)\n",
      "loss 37490.508 reward 23.021984\n",
      "tf.Tensor(\n",
      "[ 3.2757525  -3.320062    3.1867664   0.32143557 -1.9193335  -0.7498138\n",
      " -3.4735      3.3426042   3.0656369   1.4011047   0.3713109  -1.706212\n",
      " -2.2688823  -1.5321689   3.4359195  -1.4674227   1.6204242  -0.33147028\n",
      "  0.3753515  -2.1558783   1.5594732   2.969067    0.4797972  -2.3803375\n",
      "  0.48342982  2.9001212   3.3797128   0.7660457   3.1699486   3.1353035\n",
      " -3.4848294  -0.0209327  -0.7585895   3.4544134   3.0284946   3.3493507\n",
      " -1.6931267   0.33468163  1.5145622 ], shape=(39,), dtype=float32)\n",
      "loss 53810.625 reward 25.98478\n",
      "tf.Tensor(\n",
      "[ 3.769557   -3.819802    3.6867619   0.8138572  -2.4189537  -1.0739198\n",
      " -3.9686296   3.6138144   3.5655959   0.9048729  -0.02797845 -1.6234353\n",
      " -2.7641628  -1.6771264   3.9342537  -1.7282424   1.5482491  -0.3757552\n",
      "  0.87533355 -2.4666266   1.3139694   2.6090994  -0.01422077 -2.8803296\n",
      "  0.58736145  3.3997064   3.8342383   0.7221955   3.1887853   3.6057904\n",
      " -3.9847894  -0.52032554 -1.2559032   3.9525456   3.504151    3.7561805\n",
      " -2.1884317   0.38009602  1.977912  ], shape=(39,), dtype=float32)\n",
      "loss 76160.48 reward 30.594267\n",
      "tf.Tensor(\n",
      "[ 4.267296   -4.3197746   4.186762    1.3121614  -2.9188704  -1.1755085\n",
      " -4.4648347   3.6829677   4.0655932   0.4051656  -0.49839696 -1.1891341\n",
      " -3.2637799  -1.7228898   4.4332104  -1.8629024   1.3129042  -0.45225412\n",
      "  1.3753333  -2.701814    0.95023346  2.1208153  -0.51265717 -3.3803291\n",
      "  0.8312583   3.8996758   4.297476    0.3799628   2.7794957   4.08822\n",
      " -4.4847727  -1.0202703  -1.7554495   4.45082     3.995889    4.1167583\n",
      " -2.6878252   0.39370486  2.41017   ], shape=(39,), dtype=float32)\n",
      "loss 103612.89 reward 36.161983\n",
      "tf.Tensor(\n",
      "[ 4.7665505  -4.8197727   4.686762    1.8117422  -3.4188504  -0.7286314\n",
      " -4.9623203   3.8129802   4.5655932  -0.0948126  -0.99172795 -0.6924305\n",
      " -3.763764   -1.5585431   4.9325504  -1.6993315   0.93591344 -0.55865526\n",
      "  1.8753333  -2.6530304   0.52602834  1.6213353  -1.0120817  -3.8803291\n",
      "  1.233526    4.3996744   4.7780423  -0.0951291   2.2849765   4.5804625\n",
      " -4.9847655  -1.5202646  -2.255376    4.948886    4.493804    4.40919\n",
      " -3.1877534   0.43998373  2.717875  ], shape=(39,), dtype=float32)\n",
      "loss 137954.44 reward 42.680836\n",
      "tf.Tensor(\n",
      "[ 5.266283   -5.3197727   5.186762    2.3116345  -3.9188454  -0.22913054\n",
      " -5.4608197   4.2660966   5.0655932  -0.59481096 -1.4905682  -0.19253996\n",
      " -4.2637634  -1.1434134   5.4320445  -1.2554789   0.4768791  -0.69367707\n",
      "  2.3753333  -2.1919732   0.07346663  1.1213474  -1.5117414  -4.380329\n",
      "  1.711151    4.8996744   5.2710414  -0.5922374   1.7852061   5.0781913\n",
      " -5.484762   -2.020264   -2.7553642   5.446241    4.9933434   4.557349\n",
      " -3.6877444   0.65181404  2.6319492 ], shape=(39,), dtype=float32)\n",
      "loss 178603.03 reward 49.529133\n",
      "tf.Tensor(\n",
      "[ 5.7661567  -5.8197727   5.686762    2.8116097  -4.418844    0.27086842\n",
      " -5.959876    4.765305    5.5655932  -1.0948108  -1.9903986   0.30745766\n",
      " -4.7637634  -0.6506188   5.9315233  -0.75860894 -0.01312947 -0.9220329\n",
      "  2.8753333  -1.6927172  -0.3963711   0.62134755 -2.011378   -4.880329\n",
      "  2.207665    5.3996744   5.769114   -1.0919816   1.2852149   5.5778055\n",
      " -5.9847603  -2.520264   -3.255362    5.9417725   5.493243    4.3762274\n",
      " -4.187743    1.0921183   2.1802979 ], shape=(39,), dtype=float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 231000.12 reward 57.30327\n",
      "tf.Tensor(\n",
      "[ 6.2660775  -6.3197727   6.186762    3.3116047  -4.9188437   0.7708684\n",
      " -6.459181    5.265301    6.0655932  -1.5948108  -2.490377    0.8074577\n",
      " -5.2637634  -0.15091184  6.430804   -0.25868952 -0.5112066  -1.3216025\n",
      "  3.3753333  -1.1927242  -0.8774175   0.12134755 -2.5106118  -5.380329\n",
      "  2.7072563   5.8996744   6.268692   -1.5919647   0.78521526  6.0777698\n",
      " -6.484759   -3.020264   -3.7553616   6.432226    5.9932218   3.93456\n",
      " -4.687743    1.588231    1.6821312 ], shape=(39,), dtype=float32)\n",
      "loss 292344.47 reward 65.692085\n",
      "tf.Tensor(\n",
      "[ 6.766013   -6.8197727   6.686762    3.8116038  -5.4188437   1.2708684\n",
      " -6.9585605   5.765301    6.5655932  -2.094811   -2.9903746   1.3074577\n",
      " -5.7637634   0.34908187  6.929405    0.24130952 -1.010893   -1.8088355\n",
      "  3.8753333  -0.6927242  -1.3656638  -0.37865245 -3.007299   -5.880329\n",
      "  3.207219    6.3996744   6.768618   -2.0919638   0.28521526  6.577768\n",
      " -6.984758   -3.520264   -4.2553616   6.903748    6.4932175   3.4402273\n",
      " -5.187743    2.0881014   1.1821649 ], shape=(39,), dtype=float32)\n",
      "loss 371089.5 reward 74.50472\n",
      "tf.Tensor(\n",
      "[ 7.265946   -7.3197727   7.186762    4.3116035  -5.9188437   1.7708684\n",
      " -7.4578586   6.265301    7.0655932  -2.594811   -3.4903743   1.8074577\n",
      " -6.2637634   0.8490819   7.4247904   0.7413095  -1.5108489  -2.3079848\n",
      "  4.3753333  -0.19272423 -1.8584931  -0.87865245 -3.475905   -6.380329\n",
      "  3.707216    6.8996744   7.2686076  -2.5919638  -0.21478474  7.077768\n",
      " -7.484757   -4.0202637  -4.7553616   7.2600536   6.9932165   2.940609\n",
      " -5.687743    2.588099    0.68216527], shape=(39,), dtype=float32)\n",
      "loss 464821.03 reward 84.29102\n",
      "tf.Tensor(\n",
      "[ 7.765854   -7.8197727   7.686762    4.8116035  -6.4188437   2.2708683\n",
      " -7.9567437   6.765301    7.5655932  -3.094811   -3.9903743   2.3074577\n",
      " -6.7637634   1.3490819   7.8556366   1.2413095  -2.0108435  -2.8079486\n",
      "  4.8753333   0.30727577 -2.354296   -1.3786525  -3.2940755  -6.880329\n",
      "  4.2072163   7.3996744   7.7686067  -3.0919638  -0.71478474  7.577768\n",
      " -7.9847555  -4.5202637  -5.2553616   6.8908067   7.4932165   2.4406276\n",
      " -6.187743    3.088099    0.18216527], shape=(39,), dtype=float32)\n",
      "loss 576397.25 reward 94.53189\n",
      "tf.Tensor(\n",
      "[ 8.265646   -8.319773    8.186762    5.3116035  -6.9188437   2.7708683\n",
      " -8.453932    7.265301    8.065594   -3.594811   -4.4903746   2.8074577\n",
      " -7.2637634   1.8490819   7.3556376   1.7413095  -2.5108428  -3.307947\n",
      "  5.3753333   0.8072758  -2.8514426  -1.8786525  -2.7941027  -7.380329\n",
      "  4.7072163   7.8996744   8.268606   -3.5919638  -1.2147847   8.077768\n",
      " -8.484754   -5.0202637  -5.7553616   6.3933673   7.9932165   1.9406285\n",
      " -6.687743    3.588099   -0.31783473], shape=(39,), dtype=float32)\n",
      "loss 703703.75 reward 105.35986\n",
      "tf.Tensor(\n",
      "[ 8.76484    -8.819773    8.686762    5.8116035  -7.4188437   3.2708683\n",
      " -8.93479     7.765301    8.565594   -4.094811   -4.9903746   3.3074577\n",
      " -7.7637634   2.349082    6.8556376   2.2413096  -3.0108428  -3.807947\n",
      "  5.8753333   1.3072758  -3.3491313  -2.3786526  -2.2941027  -7.880329\n",
      "  5.2072163   8.399674    8.768606   -4.091964   -1.7147847   8.577768\n",
      " -8.984751   -5.5202637  -6.2553616   5.893396    8.4932165   1.4406285\n",
      " -7.187743    4.088099   -0.81783473], shape=(39,), dtype=float32)\n",
      "loss 853774.44 reward 117.57936\n",
      "tf.Tensor(\n",
      "[ 9.259543  -9.319773   9.186762   6.3116035 -7.9188437  3.7708683\n",
      " -8.450561   8.265301   9.065594  -4.594811  -5.4903746  3.8074577\n",
      " -8.263763   2.849082   6.3556376  2.7413096 -3.5108428 -4.307947\n",
      "  6.3753333  1.8072758 -3.8469217 -2.8786526 -1.7941027 -8.380329\n",
      "  5.7072163  8.899674   9.268606  -4.591964  -2.2147846  9.077768\n",
      " -9.484743  -6.0202637 -6.7553616  5.393396   8.9932165  0.9406285\n",
      " -7.687743   4.588099  -1.3178347], shape=(39,), dtype=float32)\n",
      "loss 1021809.75 reward 130.23917\n",
      "tf.Tensor(\n",
      "[ 9.71814    -9.819773    9.686762    6.8116035  -8.418844    4.2708683\n",
      " -7.9505606   8.765301    9.565594   -5.094811   -5.9903746   4.307458\n",
      " -8.763763    3.349082    5.8556376   3.2413096  -4.010843   -4.807947\n",
      "  6.8753333   2.3072758  -4.344513   -3.3786526  -1.2941027  -8.880329\n",
      "  6.2072163   9.399674    9.768606   -5.091964   -2.7147846   9.577768\n",
      " -9.984709   -6.5202637  -7.2553616   4.893396    9.4932165   0.44062853\n",
      " -8.187743    5.088099   -1.8178347 ], shape=(39,), dtype=float32)\n",
      "loss 1219801.1 reward 143.68767\n",
      "The Objective Value 1182.0\n",
      "tf.Tensor(\n",
      "[ 0.08776999 -0.4977742   0.47044507 -0.19121407  0.49801466  0.49943945\n",
      " -0.11746719  0.46325704  0.42466632  0.1062903   0.49961397 -0.17452016\n",
      "  0.46736574  0.4994177   0.49631357 -0.41311666  0.2502341   0.07529917\n",
      " -0.11961704  0.4193245  -0.04792886 -0.18996058  0.43580636 -0.2435001\n",
      "  0.1127718   0.2616067   0.4252963   0.392552    0.3314863  -0.44363666\n",
      " -0.4999411   0.49746725  0.22371697  0.49272147  0.428179    0.4989298\n",
      "  0.4727064  -0.3693794   0.30849066], shape=(39,), dtype=float32)\n",
      "loss 11159.875 reward 18.510633\n",
      "tf.Tensor(\n",
      "[ 0.07584391 -0.99518996  0.95284116 -0.24295062  0.99393094  0.9986639\n",
      " -0.21830428  0.9276371   0.8751856   0.21908554  0.9988251  -0.26507846\n",
      "  0.94256717  0.99876726  0.9923583  -0.83817065  0.53378844  0.1799943\n",
      " -0.19617544  0.8338547  -0.16819201 -0.33557308  0.8413871  -0.5648192\n",
      "  0.2283105   0.55055356  0.8091655   0.8038146   0.65873414 -0.89093363\n",
      " -0.99988604  0.9911281   0.40404928  0.984573    0.7784364   0.9961833\n",
      "  0.93947047 -0.64983594  0.6567486 ], shape=(39,), dtype=float32)\n",
      "loss 8367.413 reward 15.777305\n",
      "tf.Tensor(\n",
      "[-0.11493772 -1.4917186   1.4469332  -0.036524    1.4771658   1.4972678\n",
      " -0.2573802   1.3939306   1.3530043   0.31226945  1.4952137  -0.19087201\n",
      "  1.4294131   1.4979206   1.4875612  -1.2837871   0.8643874   0.34863248\n",
      " -0.18765809  1.2414988  -0.4289946  -0.41566092  1.1529834  -0.98871076\n",
      "  0.34954607  0.8728144   1.0686784   1.238973    0.9916967  -1.3435969\n",
      " -1.4998366   1.453455    0.49205196  1.4755089   0.8302105   1.4787\n",
      "  1.3875059  -0.6785207   1.0608003 ], shape=(39,), dtype=float32)\n",
      "loss 7587.272 reward 12.682229\n",
      "tf.Tensor(\n",
      "[-0.49745756 -1.9865203   1.9457121   0.38068107  1.8689513   1.9940801\n",
      " -0.208964    1.8597537   1.8456283   0.36181837  1.9634433   0.06718963\n",
      "  1.9244587   1.9966476   1.9813335  -1.7497752   1.2373656   0.61209416\n",
      " -0.07043778  1.6295235  -0.8331574  -0.42565605  1.241209   -1.4686601\n",
      "  0.47295243  1.2139287   1.0469882   1.6989661   1.3471196  -1.8009553\n",
      " -1.9997907   1.5913928   0.44355252  1.9654171   0.45641604  1.7890873\n",
      "  1.7808292  -0.38679123  1.5148774 ], shape=(39,), dtype=float32)\n",
      "loss 10958.553 reward 12.384576\n",
      "tf.Tensor(\n",
      "[-0.9730805  -2.4787114   2.4455233   0.86754537  1.8514062   2.485217\n",
      " -0.07437986  2.31402     2.3435714   0.37493378  2.1549554   0.44508862\n",
      "  2.4230864   2.494524    2.4733596  -2.2290342   1.6463578   0.9799855\n",
      "  0.15115237  1.9596353  -1.3085047  -0.374464    1.025004   -1.9646182\n",
      "  0.5934048   1.543634    0.71816957  2.1800246   1.7417575  -2.2593503\n",
      " -2.499743    1.1470376   0.25761473  2.4542696  -0.03149611  1.46799\n",
      "  2.0181043   0.05570433  1.9990038 ], shape=(39,), dtype=float32)\n",
      "loss 18150.477 reward 17.008257\n",
      "tf.Tensor(\n",
      "[-1.4688566  -2.9684448   2.945496    1.3660954   1.455192    2.9570334\n",
      "  0.10722929  2.7164013   2.8430264   0.41211396  1.7873697   0.8814485\n",
      "  2.9228108   2.9911103   2.9631073  -2.7132337   2.0900483   1.4193662\n",
      "  0.4729878   2.142945   -1.802918   -0.28471914  0.6173838  -2.4637513\n",
      "  0.69651663  1.8324696   0.2578495   2.67389     2.1818097  -2.7108572\n",
      " -2.9996817   0.648358   -0.01585218  2.9425     -0.5304936   0.97742045\n",
      "  1.940478    0.53983986  2.4945517 ], shape=(39,), dtype=float32)\n",
      "loss 28766.1 reward 22.070936\n",
      "tf.Tensor(\n",
      "[-1.9680479  -3.4575706   3.4454923   1.8659699   0.9727701   3.35904\n",
      "  0.28955218  2.916712    3.342888    0.51368654  1.2984391   1.3444676\n",
      "  3.4227688   3.4862149   3.4497874  -3.1961367   2.5595212   1.8936361\n",
      "  0.8850118   2.0265667  -2.3016038  -0.22470322  0.14158961 -2.9635258\n",
      "  0.77362794  2.0536547  -0.23427656  3.1724768   2.6573465  -3.13689\n",
      " -3.4995666   0.14838105 -0.34059453  3.4299326  -1.0304031   0.47784892\n",
      "  1.567504    1.0348972   2.9933877 ], shape=(39,), dtype=float32)\n",
      "loss 41082.785 reward 26.347744\n",
      "tf.Tensor(\n",
      "[-2.467856   -3.9485455   3.9454918   2.3659604   0.47627088  3.5024395\n",
      "  0.41145617  2.5639796   3.8428547   0.6812322   0.79942334  1.8198056\n",
      "  3.922764    3.9802988   3.9317122  -3.6684809   3.043906    2.3826268\n",
      "  1.354312    1.6290581  -2.8012645  -0.2933838  -0.35290736 -3.4634526\n",
      "  0.8261407   2.1829     -0.73274946  3.672225    3.1501315  -3.496334\n",
      " -3.9992347  -0.35161862 -0.6960481   3.915348   -1.5303931  -0.02212811\n",
      "  1.0888679   1.5329201   3.4930878 ], shape=(39,), dtype=float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 56377.57 reward 30.806486\n",
      "tf.Tensor(\n",
      "[-2.9677913  -4.4423966   4.445492    2.8659596  -0.02286482  3.1134682\n",
      "  0.37691808  2.0681226   4.342847    0.868886    0.29953492  2.300735\n",
      "  4.422764    4.474532    4.4042196  -4.102288    3.5342848   2.8774307\n",
      "  1.8470919   1.1434441  -3.3011634  -0.552307   -0.8519033  -3.9634204\n",
      "  0.8998807   2.1853209  -1.2324296   4.172181    3.6485746  -3.7128513\n",
      " -4.497709   -0.85161865 -1.0689521   4.3945003  -2.0303912  -0.5221262\n",
      "  0.59129953  2.0316107   3.9930031 ], shape=(39,), dtype=float32)\n",
      "loss 76012.44 reward 36.42518\n",
      "tf.Tensor(\n",
      "[-3.4677577  -4.939118    4.945492    3.3659596  -0.522576    2.61667\n",
      "  0.08087942  1.5681965   4.842845    0.93130213 -0.20044798  2.784508\n",
      "  4.922764    4.970166    4.8578377  -4.384032    4.0265064   3.374746\n",
      "  2.3459733   0.644796   -3.8011289  -0.95735586 -1.3517592  -4.4634004\n",
      "  1.1034945   2.014761   -1.7323489   4.6721725   4.148307   -3.7186477\n",
      " -4.986873   -1.3516186  -1.457737    4.852429   -2.5303905  -1.022126\n",
      "  0.09149289  2.5299659   4.4929776 ], shape=(39,), dtype=float32)\n",
      "loss 100493.71 reward 42.565464\n",
      "tf.Tensor(\n",
      "[-3.9677298  -5.4378285   5.445492    3.8659596  -1.022441    2.116728\n",
      " -0.38108182  1.0681977   5.3428445   0.57171893 -0.700444    3.2695236\n",
      "  5.422764    5.4677515   5.27108    -4.1625433   4.517871    3.8732927\n",
      "  2.8458564   0.14488676 -4.3011155  -1.4227618  -1.8517416  -4.9633827\n",
      "  1.4944748   1.6742985  -2.232324    5.1721706   4.6482673  -3.5012124\n",
      " -5.381977   -1.8516186  -1.8624823   5.186274   -3.03039    -1.5221258\n",
      " -0.40849683  3.0255938   4.9929695 ], shape=(39,), dtype=float32)\n",
      "loss 129861.41 reward 48.851154\n",
      "tf.Tensor(\n",
      "[-4.4676914  -5.9374704   5.945492    4.3659596  -1.5223618   1.616729\n",
      " -0.87637556  0.5681977   5.8428445   0.07994249 -1.2004423   3.7538624\n",
      "  5.922764    5.9668665   5.5804663  -3.6739159   5.002441    4.372442\n",
      "  3.3458478  -0.35510886 -4.8011093  -1.9081907  -2.3517394  -5.4633574\n",
      "  1.9734776   1.2395136  -2.7323143   5.67217     5.1482625  -3.100199\n",
      " -5.2789183  -2.3516188  -2.2749956   4.729938   -3.5303893  -2.0221257\n",
      " -0.9084965   3.49503     5.4929667 ], shape=(39,), dtype=float32)\n",
      "loss 163302.84 reward 55.57534\n",
      "tf.Tensor(\n",
      "[-4.967606   -6.4373875   6.445492    4.8659596  -2.022311    1.116729\n",
      " -1.3758799   0.06819773  6.3428445  -0.41949648 -1.7004409   4.2322383\n",
      "  6.422764    6.4666376   5.52616    -3.1741514   5.4470997   4.871846\n",
      "  3.8458474  -0.85510874 -5.301105   -2.3997414  -2.8517392  -5.9632807\n",
      "  2.470629    0.7605814  -3.2323093   6.17217     5.648262   -2.616101\n",
      " -4.838769   -2.8516188  -2.6949067   4.2299967  -4.030385   -2.5221255\n",
      " -1.4084965   3.470376    5.9929647 ], shape=(39,), dtype=float32)\n",
      "loss 204011.7 reward 63.471317\n",
      "tf.Tensor(\n",
      "[-5.467303   -6.9373713   6.945492    5.3659596  -2.522277    0.616729\n",
      " -1.8758309  -0.43180227  6.8428445  -0.9194297  -2.200438    4.686592\n",
      "  6.922764    6.9665947   5.083628   -2.6741557   5.620357    5.3713455\n",
      "  4.345847   -1.3551087  -5.8011003  -2.8923132  -3.3517392  -6.462766\n",
      "  2.9702818   0.2665122  -3.7323058   6.67217     6.148262   -2.1175194\n",
      " -4.34354    -3.3516188  -3.1218793   3.7299967  -4.5302973  -3.0221238\n",
      " -1.9084965   2.9707417   6.4929633 ], shape=(39,), dtype=float32)\n",
      "loss 253562.86 reward 71.91094\n",
      "tf.Tensor(\n",
      "[-5.9655285  -7.437369    7.445492    5.8659596  -3.022254    0.11672902\n",
      " -2.3758261  -0.9318023   7.3428445  -1.4194148  -2.700425    4.985111\n",
      "  7.422764    7.466589    4.5865235  -2.1741557   5.2036133   5.8708353\n",
      "  4.845847   -1.8551087  -6.3010902  -3.3815317  -3.8517392  -6.9553604\n",
      "  3.4702432  -0.23182446 -4.2323027   7.17217     6.648262   -1.6176049\n",
      " -3.8437963  -3.8516188  -3.5531592   3.2299967  -5.0244665  -3.5220866\n",
      " -2.4084964   2.4707417   6.9929614 ], shape=(39,), dtype=float32)\n",
      "loss 313096.94 reward 80.52078\n",
      "tf.Tensor(\n",
      "[-6.4488144  -7.9373684   7.945492    6.3659596  -3.5222387  -0.38327098\n",
      " -2.8758256  -1.4318023   7.8428445  -1.919407   -3.2002993   4.509995\n",
      "  7.922764    7.9665885   4.0866218  -1.6741557   4.706025    6.3701973\n",
      "  5.345847   -2.3551087  -6.8010554  -3.8484561  -4.351739   -7.241316\n",
      "  3.9702394  -0.73128545 -4.7322984   7.67217     7.148262   -1.1176085\n",
      " -3.343806   -4.351619   -3.9750035   2.7299967  -4.7695885  -4.019613\n",
      " -2.9084964   1.9707417   7.4929576 ], shape=(39,), dtype=float32)\n",
      "loss 379091.47 reward 89.09342\n",
      "tf.Tensor(\n",
      "[-6.7570076  -8.437368    8.445492    6.8659596  -4.022229   -0.883271\n",
      " -3.3758256  -1.9318023   8.342844   -2.4193788  -3.6985316   4.010361\n",
      "  8.422764    8.466589    3.586624   -1.1741557   4.2060647   6.868919\n",
      "  5.845847   -2.8551087  -7.3008556  -4.115268   -4.851739   -6.7461977\n",
      "  4.4702387  -1.2310256  -5.2322907   8.172171    7.648262   -0.61760855\n",
      " -2.843806   -4.851619   -4.2986207   2.2299967  -4.2695885  -4.304008\n",
      " -3.4084964   1.4707417   7.9929466 ], shape=(39,), dtype=float32)\n",
      "loss 452360.16 reward 97.406334\n",
      "tf.Tensor(\n",
      "[-7.250569   -8.937368    8.945492    7.3659596  -4.522225   -1.383271\n",
      " -3.8758256  -2.4318023   8.842844   -2.9191399  -4.1620545   3.5103664\n",
      "  8.922764    8.966589    3.086624   -0.6741557   3.706065    7.3654294\n",
      "  6.345847   -3.3551087  -7.7992373  -3.6158497  -5.351739   -6.2462\n",
      "  4.9702387  -1.7308805  -5.7322764   8.672171    8.148262   -0.11760855\n",
      " -2.343806   -5.351619   -4.244557    1.7299967  -3.7695885  -4.3200603\n",
      " -3.9084964   0.97074175  8.492877  ], shape=(39,), dtype=float32)\n",
      "loss 533655.0 reward 105.55563\n",
      "tf.Tensor(\n",
      "[-7.750377   -9.437368    9.445492    7.8659596  -5.022224   -1.883271\n",
      " -4.375826   -2.9318023   9.342844   -3.4144063  -4.4934063   3.0103664\n",
      "  9.422764    9.466589    2.586624   -0.17415571  3.206065    7.853315\n",
      "  6.845847   -3.8551087  -8.2785     -3.1158497  -5.851739   -5.7462\n",
      "  5.4702387  -2.2307982  -6.2322497   9.172171    8.648262    0.38239145\n",
      " -1.843806   -5.851619   -3.7660394   1.2299967  -3.2695885  -4.817389\n",
      " -4.4084964   0.47074175  8.991917  ], shape=(39,), dtype=float32)\n",
      "loss 620507.2 reward 114.10518\n",
      "tf.Tensor(\n",
      "[-8.250367   -9.937368    9.945492    8.365959   -5.522224   -2.383271\n",
      " -4.875826   -3.4318023   9.842844   -3.7235494  -4.9930205   2.5103664\n",
      "  9.922764    9.966589    2.086624    0.3258443   2.706065    8.313598\n",
      "  7.345847   -4.3551087  -7.8094172  -2.6158497  -6.351739   -5.2462\n",
      "  5.9702387  -2.7307458  -6.7322063   9.672171    9.148262    0.88239145\n",
      " -1.343806   -6.351619   -3.2663126   0.7299967  -2.7695885  -5.317383\n",
      " -4.9084964  -0.02925825  9.460274  ], shape=(39,), dtype=float32)\n",
      "loss 709687.6 reward 121.76273\n",
      "The Objective Value 967.0\n",
      "tf.Tensor(\n",
      "[ 0.49949953  0.487451    0.03956795 -0.16757956  0.49546424  0.49427184\n",
      "  0.2468123   0.46030924  0.03053784  0.4901187   0.30521327  0.49982357\n",
      "  0.4960347   0.33485946  0.48809844 -0.36563447  0.35196325  0.27948543\n",
      "  0.38506052  0.4349558  -0.22094436  0.4851822  -0.35899428  0.48955584\n",
      "  0.49894103  0.47491845  0.24718642  0.3076996   0.0471057   0.49999315\n",
      " -0.49911958  0.23788796  0.23782368  0.49891567 -0.4692102   0.48198175\n",
      "  0.32397318  0.46171245  0.0322597 ], shape=(39,), dtype=float32)\n",
      "loss 12845.219 reward 20.156254\n",
      "tf.Tensor(\n",
      "[ 0.9985321   0.97626233  0.2321403  -0.20674859  0.9872559   0.98444474\n",
      "  0.393999    0.9058858   0.16154861  0.96954966  0.60345554  0.999481\n",
      "  0.9917924   0.6760585   0.97775924 -0.6892427   0.72756034  0.5854374\n",
      "  0.81398976  0.84043384 -0.42174667  0.9695784  -0.716746    0.97372437\n",
      "  0.99781764  0.92512435  0.45704007  0.67213964  0.27374738  0.9999793\n",
      " -0.9986112   0.4043916   0.37749958  0.9978038  -0.94269395  0.94210654\n",
      "  0.5580953   0.9025399   0.24303265], shape=(39,), dtype=float32)\n",
      "loss 8621.229 reward 16.368044\n",
      "tf.Tensor(\n",
      "[ 1.4939786   1.4653072   0.6216699   0.02118587  1.4562892   1.4536679\n",
      "  0.33625945  1.3041502   0.45530415  1.3596331   0.85143167  1.4980139\n",
      "  1.4871573   1.0477666   1.4680876  -0.88494515  1.1324157   0.9444277\n",
      "  1.2888298   1.1662934  -0.5384617   1.454768   -1.0800557   1.4370879\n",
      "  1.496554    1.2561711   0.57215273  1.1041921   0.69371295  1.4999238\n",
      " -1.4984338   0.35759884  0.2598705   1.4965248  -1.4111382   1.214475\n",
      "  0.55676246  1.2556596   0.64778423], shape=(39,), dtype=float32)\n",
      "loss 8018.446 reward 13.018307\n",
      "tf.Tensor(\n",
      "[ 1.9430568   1.9520411   1.1039886   0.46050557  1.7556672   1.7877861\n",
      "  0.03125218  1.5602798   0.87407476  1.1861328   1.0006876   1.9844451\n",
      "  1.9817551   1.4620975   1.9564961  -0.79905295  1.5702231   1.3630332\n",
      "  1.7841504   1.3116609  -0.46908435  1.9445     -1.4472436   1.8130121\n",
      "  1.9950386   1.1812073   0.5047981   1.580389    1.1827241   1.9994117\n",
      " -1.9983978  -0.01376501 -0.13389358  1.9948     -1.8498032   0.8388101\n",
      "  0.23866814  1.3000712   1.1304778 ], shape=(39,), dtype=float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 15417.628 reward 15.052294\n",
      "tf.Tensor(\n",
      "[ 1.8803056   2.429493    1.6023804   0.9538477   1.4812077   1.5842271\n",
      " -0.4166732   1.481786    1.3441124   0.70000017  1.050848    2.2948146\n",
      "  2.474198    1.9135011   2.4353647  -0.41989294  2.0428128   1.8254925\n",
      "  2.2836902   1.1812514  -0.14652032  2.4400325  -1.7904837   1.8899441\n",
      "  2.493074    0.7550729   0.20928553  2.074569    1.6818498   2.4884923\n",
      " -2.4983938  -0.5044143  -0.6181054   2.4923334  -2.1514928   0.34097162\n",
      " -0.22658768  0.92151713  1.6279794 ], shape=(39,), dtype=float32)\n",
      "loss 27838.264 reward 18.5301\n",
      "tf.Tensor(\n",
      "[ 1.3969979   2.873269    2.1022565   1.4532794   0.99335694  1.1064597\n",
      " -0.9066293   1.0935489   1.8320366   0.20034596  1.0781059   1.9267173\n",
      "  2.9607427   2.3886425   2.872283    0.0585525   2.5340252   2.3118148\n",
      "  2.7836595   0.84274924  0.31292173  2.9386225  -2.036337    1.551803\n",
      "  2.9901388   0.26337406 -0.23468545  2.5735338   2.1817977   2.6709018\n",
      " -2.9983935  -1.004189   -1.1162198   2.9883995  -2.0270586  -0.1590082\n",
      " -0.72108567  0.43123612  2.127459  ], shape=(39,), dtype=float32)\n",
      "loss 43255.168 reward 23.88884\n",
      "tf.Tensor(\n",
      "[ 0.8972559   3.180392    2.6022468   1.953229    0.4936984   0.6076659\n",
      " -1.4051927   0.6130749   2.3266945  -0.2996437   1.1775246   1.4303428\n",
      "  3.4293065   2.8770025   3.0883708   0.5551138   3.0315692   2.807551\n",
      "  3.283658    0.41571537  0.8058884   3.4382627  -2.060086    1.07113\n",
      "  3.4848576  -0.23547065 -0.7243208   3.073377    2.6817946   2.200437\n",
      " -3.4983935  -1.5041869  -1.6159928   3.4814966  -1.5736744  -0.659008\n",
      " -1.220107   -0.06830904  2.6272383 ], shape=(39,), dtype=float32)\n",
      "loss 65084.996 reward 31.058863\n",
      "tf.Tensor(\n",
      "[ 0.39725894  3.0515141   3.102246    2.4532237  -0.006295    0.10773307\n",
      " -1.9050268   0.11626378  2.8239708  -0.7996433   1.3999722   0.93042004\n",
      "  3.8307364   3.3717897   2.7256684   1.0545402   3.5309815   3.3062453\n",
      "  3.783658   -0.04194874  1.3047214   3.938186   -1.8073676   0.5726787\n",
      "  3.9729977  -0.73522663 -1.2227443   3.573355    3.1817946   1.7007328\n",
      " -3.9983935  -2.0041869  -2.1159637   3.9690192  -1.0761573  -1.159008\n",
      " -1.7198905  -0.5682944   3.1270518 ], shape=(39,), dtype=float32)\n",
      "loss 94264.56 reward 39.012238\n",
      "tf.Tensor(\n",
      "[-0.10274103  2.5816483   3.602246    2.9532232  -0.5062949  -0.39226222\n",
      " -2.4050086  -0.3831648   3.3224404  -1.2996433   1.738738    0.4304217\n",
      "  3.8774881   3.8695204   2.2288883   1.5544249   4.030855    3.8058376\n",
      "  4.283658   -0.50531185  1.8045008   4.4381723  -1.3906534   0.0727748\n",
      "  4.4372206  -1.2351437  -1.7225275   4.073352    3.6817946   1.2007349\n",
      " -4.4983935  -2.5041869  -2.6159596   4.4451227  -0.57625955 -1.659008\n",
      " -2.2198317  -1.068294    3.6267848 ], shape=(39,), dtype=float32)\n",
      "loss 133573.89 reward 47.42902\n",
      "tf.Tensor(\n",
      "[-0.602741    2.0828128   4.1022463   3.4532232  -1.006295   -0.89226174\n",
      " -2.9050064  -0.8830366   3.8214006  -1.7996433   2.1625187  -0.06957826\n",
      "  3.3874946   4.36855     1.7289206   2.0543938   4.5308313   4.3057065\n",
      "  4.783658   -0.95520425  2.3044436   4.9381704  -0.9109343  -0.42722073\n",
      "  4.723736   -1.7350941  -2.2225006   4.5733514   4.1817946   0.70073485\n",
      " -4.9983935  -3.0041869  -3.115959    4.8998013  -0.07626393 -2.159008\n",
      " -2.7198105  -1.568294    4.126199  ], shape=(39,), dtype=float32)\n",
      "loss 184040.62 reward 56.185074\n",
      "tf.Tensor(\n",
      "[-1.102741    1.5828599   4.6022463   3.9532232  -1.506295   -1.3922616\n",
      " -3.4050062  -1.3829966   4.3204255  -2.2996433   2.6405442  -0.5695783\n",
      "  2.8875384   4.8681636   1.2289207   2.5543823   5.0308275   4.80566\n",
      "  5.283658   -1.3546045   2.8044193   5.4381704  -0.41392276 -0.9272206\n",
      "  4.226221   -2.2350378  -2.7224977   5.0733514   4.6817946   0.20073485\n",
      " -5.4983935  -3.5041869  -3.6159587   5.3217525   0.4237358  -2.659008\n",
      " -3.2197986  -2.068294    4.624446  ], shape=(39,), dtype=float32)\n",
      "loss 247252.56 reward 65.30596\n",
      "tf.Tensor(\n",
      "[-1.602741    1.0828617   5.1022463   4.453223   -2.006295   -1.8922616\n",
      " -3.9050062  -1.8829792   4.819105   -2.7996433   3.1365426  -1.0695783\n",
      "  2.3875384   5.3680263   0.7289207   3.054377    5.530827    5.305641\n",
      "  5.783658   -1.6848572   3.304404    5.9381704   0.0857943  -1.4272206\n",
      "  3.7262216  -2.734908   -3.2224975   5.5733514   5.1817946  -0.29926515\n",
      " -5.9983935  -4.0041866  -4.1159587   5.649543    0.9237358  -3.159008\n",
      " -3.7197876  -2.568294    5.1174483 ], shape=(39,), dtype=float32)\n",
      "loss 328417.94 reward 74.79113\n",
      "tf.Tensor(\n",
      "[-2.102741    0.58286166  5.6022463   4.953223   -2.506295   -2.3922615\n",
      " -4.4050064  -2.382968    5.3165693  -3.2996433   3.6361516  -1.5695783\n",
      "  1.8875384   5.867983    0.2289207   3.5543742   6.030827    5.8056326\n",
      "  6.283658   -2.1084616   3.8043897   6.4381704   0.58577764 -1.9272206\n",
      "  3.2262216  -3.2343109  -3.7224975   6.0733514   5.6817946  -0.79926515\n",
      " -6.4983935  -4.5041866  -4.6159587   5.571973    1.4237359  -3.659008\n",
      " -4.2197714  -3.068294    5.5761805 ], shape=(39,), dtype=float32)\n",
      "loss 430706.72 reward 84.976776\n",
      "tf.Tensor(\n",
      "[-2.602741    0.08286166  6.1022463   5.453223   -3.006295   -2.8922615\n",
      " -4.9050064  -2.8829563   5.8095074  -3.7996433   4.136133   -2.0695782\n",
      "  1.3875384   6.3679705  -0.2710793   4.0543723   6.530827    6.3056283\n",
      "  6.783658   -2.5989661   4.3043694   6.9381704   1.085777   -2.4272206\n",
      "  2.7262216  -3.7286823  -4.2224975   6.5733514   6.1817946  -1.2992651\n",
      " -6.9983935  -5.0041866  -5.1159587   5.0806336   1.9237359  -4.159008\n",
      " -4.719731   -3.568294    5.571016  ], shape=(39,), dtype=float32)\n",
      "loss 558341.9 reward 96.254425\n",
      "tf.Tensor(\n",
      "[-3.102741   -0.41713834  6.6022463   5.953223   -3.506295   -3.3922613\n",
      " -5.4050064  -3.382934    6.278428   -4.2996435   4.6361327  -2.5695782\n",
      "  0.88753843  6.867967   -0.7710793   4.5543704   7.030827    6.8056264\n",
      "  7.283658   -3.0977538   4.8043222   7.4381704   1.585777   -2.9272206\n",
      "  2.2262216  -4.148461   -4.7224975   7.0733514   6.6817946  -1.7992651\n",
      " -7.4983935  -5.5041866  -5.6159587   4.580722    2.4237359  -4.659008\n",
      " -5.2195325  -4.068294    5.071026  ], shape=(39,), dtype=float32)\n",
      "loss 717733.6 reward 109.43769\n",
      "tf.Tensor(\n",
      "[-3.602741   -0.91713834  7.1022463   6.453223   -4.006295   -3.8922598\n",
      " -5.9050064  -3.8828506   6.493915   -4.7996435   5.1361327  -3.0695782\n",
      "  0.38753843  7.367966   -1.2710793   5.0543675   7.530827    7.3056254\n",
      "  7.783658   -3.5975883   5.304139    7.9381704   2.085777   -3.4272206\n",
      "  1.7262216  -4.626015   -5.2224975   7.5733514   7.1817946  -2.2992651\n",
      " -7.9983935  -6.0041866  -6.115958    4.080723    2.9237359  -5.159008\n",
      " -5.717759   -4.568294    4.571026  ], shape=(39,), dtype=float32)\n",
      "loss 915356.94 reward 123.44225\n",
      "tf.Tensor(\n",
      "[-4.1027412  -1.4171383   7.6022463   6.953223   -4.506295   -4.392236\n",
      " -6.4050064  -4.3822308   5.9994607  -5.2996297   5.6361327  -3.5695782\n",
      " -0.11246157  7.867966   -1.7710793   5.5543633   8.030827    7.805625\n",
      "  8.283658   -4.0975604   5.802892    8.43817     2.585777   -3.9272206\n",
      "  1.2262216  -5.12503    -5.7224975   8.073351    7.6817946  -2.7992651\n",
      " -8.498394   -6.5041866  -6.6159506   3.5807228   3.4237359  -5.659008\n",
      " -6.1894855  -5.068294    4.071026  ], shape=(39,), dtype=float32)\n",
      "loss 1157694.8 reward 137.96977\n",
      "tf.Tensor(\n",
      "[-4.6027412  -1.9171383   8.102246    7.453223   -5.006295   -4.891207\n",
      " -6.9050064  -4.8741016   5.4994645  -5.79299     6.1361327  -4.069578\n",
      " -0.61246157  8.367966   -2.2710793   6.0543537   8.530827    8.305625\n",
      "  8.783658   -4.597554    6.2867217   8.93817     3.085777   -4.4272203\n",
      "  0.72622156 -5.625002   -6.2224975   8.573351    8.181795   -3.2992651\n",
      " -8.998394   -7.0041866  -7.115733    3.0807228   3.9237359  -6.159008\n",
      " -6.4411745  -5.568294    3.5710258 ], shape=(39,), dtype=float32)\n",
      "loss 1452748.6 reward 153.28328\n",
      "tf.Tensor(\n",
      "[-5.1027412  -2.4171383   8.602246    7.953223   -5.506295   -5.24622\n",
      " -7.4050064  -5.2920246   4.9994645  -5.3641257   6.6361327  -4.569578\n",
      " -1.1124616   8.867966   -2.7710793   6.5543294   9.030827    8.805625\n",
      "  9.283658   -5.097552    6.1526184   9.43817     3.585777   -4.9272203\n",
      "  0.22622156 -6.1250014  -6.7224975   9.073351    8.681795   -3.7992651\n",
      " -9.498394   -7.5041866  -7.602376    2.5807228   4.4237356  -6.659008\n",
      " -6.938435   -6.068294    3.0710258 ], shape=(39,), dtype=float32)\n",
      "loss 1807412.4 reward 170.45229\n",
      "tf.Tensor(\n",
      "[-5.6027412  -2.9171383   9.102246    8.453222   -6.006295   -4.74622\n",
      " -7.9050064  -5.7285233   4.4994645  -4.864131    7.1361327  -5.069578\n",
      " -1.6124616   9.367966   -3.2710793   7.054289    9.530827    9.305625\n",
      "  9.783658   -5.5975475   5.6526184   9.93817     4.0857773  -5.4272203\n",
      " -0.27377844 -6.6250014  -7.2224975   9.573351    9.181795   -4.299265\n",
      " -9.998394   -8.004187   -7.2848425   2.0807228   4.9237356  -7.159008\n",
      " -7.4382215  -6.568294    2.5710258 ], shape=(39,), dtype=float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 2230895.8 reward 188.53806\n",
      "The Objective Value 1150.0\n",
      "tf.Tensor(\n",
      "[ 0.4404811  -0.46634158  0.25607416  0.06899734  0.48636246 -0.16094251\n",
      " -0.2113663   0.4990534   0.3666292   0.45479354  0.49953118  0.4994712\n",
      "  0.4981675   0.49651098  0.23913431  0.49992076  0.15001254  0.49205866\n",
      "  0.48332748  0.46070814  0.46058807  0.49675235  0.18551731  0.40711853\n",
      "  0.492923    0.4798052   0.468361    0.46985206 -0.29618508  0.42369032\n",
      "  0.10896087  0.30714425  0.496258    0.4931287  -0.39823845  0.27230072\n",
      "  0.25615653  0.4987873   0.4203163 ], shape=(39,), dtype=float32)\n",
      "loss 12920.937 reward 21.07733\n",
      "tf.Tensor(\n",
      "[ 0.8461113  -0.9360143   0.60759425  0.324032    0.94764566 -0.37331742\n",
      " -0.45293322  0.99762404  0.77881134  0.8546814   0.99846536  0.9984611\n",
      "  0.99529946  0.99274325  0.48687258  0.99980485  0.26914912  0.98456955\n",
      "  0.9727012   0.915429    0.8926675   0.9934298   0.29982567  0.741148\n",
      "  0.9833115   0.9394753   0.9094391   0.9335244  -0.50035334  0.8322772\n",
      "  0.10067715  0.40289837  0.98572993  0.98279905 -0.73314285  0.46218818\n",
      "  0.36061245  0.99675393  0.82666063], shape=(39,), dtype=float32)\n",
      "loss 6669.409 reward 16.20463\n",
      "tf.Tensor(\n",
      "[ 1.1367005  -1.414408    1.0598563   0.75869054  1.2012459  -0.6371421\n",
      " -0.72653055  1.4942552   1.2362893   0.972204    1.4917388   1.4949195\n",
      "  1.4880972   1.4885364   0.70578516  1.4995698   0.26077783  1.4776809\n",
      "  1.4685354   1.3521453   1.2129887   1.4901142   0.25798446  0.8193915\n",
      "  1.4647058   1.2890024   1.2260981   1.3772823  -0.46754017  1.2058237\n",
      " -0.1289055   0.05572709  1.4181803   1.4594542  -0.812067    0.4177275\n",
      "  0.13110644  1.490223    1.1829711 ], shape=(39,), dtype=float32)\n",
      "loss 4268.9507 reward 10.67548\n",
      "tf.Tensor(\n",
      "[ 1.1881293  -1.9026982   1.5511209   1.2495656   0.8540223  -0.9080092\n",
      " -1.0006311   1.982431    1.717784    0.59620786  1.8890737   1.9743472\n",
      "  1.95783     1.9835007   0.810443    1.9989278   0.03782544  1.9715123\n",
      "  1.9676247   1.7425528   1.2129883   1.9867812   0.00824358  0.5000645\n",
      "  1.915828    1.2083558   1.1641506   1.7566128  -0.14044943  1.501739\n",
      " -0.5412948  -0.43573475  1.4449407   1.8879211  -0.4728869   0.07966354\n",
      " -0.32325533  1.9482212   1.383907  ], shape=(39,), dtype=float32)\n",
      "loss 6499.6035 reward 9.745711\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[ 1.0238174  -2.3975704   2.0498514   1.7485421   0.36192402 -1.0864521\n",
      " -1.1870518   2.4379303   2.2072296   0.1034148   1.5910025   2.322036\n",
      "  2.271971    2.4773636   0.6646931   2.496652   -0.35851285  2.465819\n",
      "  2.467505    2.0245867   0.857018    2.483383   -0.3900259   0.02415863\n",
      "  2.270045    0.77224594  0.7682525   1.9162097   0.3187542   1.6634598\n",
      " -1.0204098  -0.9354952   1.014137    2.1653473   0.01043546 -0.3864736\n",
      " -0.81927556  2.0917315   1.2301053 ], shape=(39,), dtype=float32)\n",
      "loss 14194.878 reward 13.797636\n",
      "tf.Tensor(\n",
      "[ 0.770296   -2.895532    2.5496788   2.2484229  -0.13767487 -0.9608612\n",
      " -1.1437893   2.8052688   2.6973877  -0.39627126  1.0966623   2.1959596\n",
      "  2.0339086   2.9705997   0.2600099   2.9866607  -0.8256157   2.9598494\n",
      "  2.9674928   2.0971699   0.38492146  2.9799154  -0.84666455 -0.4734339\n",
      "  2.3705242   0.27870193  0.28920433  1.6747631   0.8099321   1.6407611\n",
      " -1.5156931  -1.4354885   0.5204308   2.1518633   0.5091745  -0.880198\n",
      " -1.3189722   1.6780853   0.8000419 ], shape=(39,), dtype=float32)\n",
      "loss 18924.248 reward 16.480417\n",
      "tf.Tensor(\n",
      "[ 0.53506327 -3.3946822   3.0496514   2.748409   -0.6376443  -0.513911\n",
      " -0.807376    3.0302777   3.181401   -0.89625347  0.59684193  1.7726551\n",
      "  1.5533947   3.4640603  -0.2295827   3.4381592  -1.3119034   3.452705\n",
      "  3.4674914   1.923723   -0.10856849  3.4761608  -1.3180578  -0.9731791\n",
      "  2.1121864  -0.22053885 -0.20424736  1.2203983   1.3079219   1.4059942\n",
      " -2.0146036  -1.9354882   0.02142933  1.8824458   1.0090647  -1.3787004\n",
      " -1.8189411   1.1822932   0.30957618], shape=(39,), dtype=float32)\n",
      "loss 23575.117 reward 18.81376\n",
      "tf.Tensor(\n",
      "[ 0.43060997 -3.894267    3.5496461   3.2484076  -1.13764    -0.01554188\n",
      " -0.3336117   3.0853426   3.6352823  -1.3962518   0.0968529   1.2904012\n",
      "  1.0544335   3.9583397  -0.7289692   3.7339547  -1.80179     3.9428983\n",
      "  3.9674914   1.5734491  -0.60617816  3.9716256  -1.782951   -1.4731457\n",
      "  1.6661952  -0.7204164  -0.70032024  0.7259462   1.8073981   1.0110624\n",
      " -2.514327   -2.4354882  -0.4782142   1.4917575   1.5090511  -1.8781884\n",
      " -2.3189354   0.6824838  -0.1889593 ], shape=(39,), dtype=float32)\n",
      "loss 28825.938 reward 21.284046\n",
      "tf.Tensor(\n",
      "[ 0.5729885  -4.3940225   4.049645    3.7484076  -1.6376388   0.484442\n",
      "  0.164334    2.9334896   3.924794   -1.8962516  -0.40314564  0.7969971\n",
      "  0.5544927   4.4536576  -1.2289457   3.6723158  -2.2865112   4.4264474\n",
      "  4.467491    1.1370349  -1.1046277   4.4653845  -2.20091    -1.9731396\n",
      "  1.1759028  -1.220387   -1.1954024   0.22655013  2.3072326   0.54515904\n",
      " -3.0142462  -2.9354882  -0.9778949   1.0584702   2.0090485  -2.377933\n",
      " -2.8189335   0.18249336 -0.68864524], shape=(39,), dtype=float32)\n",
      "loss 35636.97 reward 23.569231\n",
      "tf.Tensor(\n",
      "[ 0.9447148  -4.8938446   4.5496445   4.2484074  -2.137638    0.984442\n",
      "  0.6642487   2.5861742   3.6835704  -2.3962514  -0.9031452   0.30133456\n",
      "  0.05449671  4.9499354  -1.728945    3.3008294  -2.7388496   4.891169\n",
      "  4.967491    0.6664712  -1.6027575   4.955752   -2.3939662  -2.473138\n",
      "  0.67762196 -1.7203757  -1.6819643  -0.27338392  2.807168    0.05604514\n",
      " -3.514218   -3.4354882  -1.4771188   0.6190965   2.5090475  -2.8777483\n",
      " -3.318932   -0.31750607 -1.1885356 ], shape=(39,), dtype=float32)\n",
      "loss 46127.156 reward 27.454988\n",
      "tf.Tensor(\n",
      "[ 1.4175999  -5.3936725   5.0496445   4.7484074  -2.637637    1.484442\n",
      "  1.1642467   2.1437123   3.2005792  -2.8962514  -1.4031448  -0.19317648\n",
      " -0.44550297  5.4470186  -2.228945    2.8324132  -3.0165486   5.2947025\n",
      "  5.467491    0.18383673 -2.0986037   5.4386163  -2.074523   -2.9731374\n",
      "  0.17793575 -2.2203684  -2.10446    -0.773376    3.3071368  -0.4402735\n",
      " -4.0142055  -3.9354882  -1.9717577   0.20684657  3.009047   -3.3775556\n",
      " -3.8189294  -0.8175061  -1.6884652 ], shape=(39,), dtype=float32)\n",
      "loss 64858.34 reward 34.928814\n",
      "tf.Tensor(\n",
      "[ 1.9138211  -5.8934374   5.5496445   5.2484074  -3.1376326   1.984442\n",
      "  1.6642467   1.6720052   2.701118   -3.3962512  -1.903144   -0.6795508\n",
      " -0.94550294  5.9448223  -2.728945    2.3419063  -2.9547045   5.468165\n",
      "  5.967491   -0.30102247 -2.5827804   5.8985596  -1.5839165  -3.4731371\n",
      " -0.3220067  -2.720361   -2.0339224  -1.2733749   3.80712    -0.9388899\n",
      " -4.5141983  -4.435488   -2.3754227  -0.09072948  3.5090466  -3.8772836\n",
      " -4.318918   -1.3175061  -2.1883736 ], shape=(39,), dtype=float32)\n",
      "loss 93843.89 reward 42.78342\n",
      "tf.Tensor(\n",
      "[ 2.4134321  -6.392996    6.0496445   5.7484074  -3.6376061   2.484442\n",
      "  2.1642466   1.1964167   2.20113    -3.8962502  -2.40314    -1.1166357\n",
      " -1.445503    6.443206   -3.228945    1.845413   -2.811956    5.10161\n",
      "  6.467491   -0.77931154 -2.9908843   6.261813   -1.0841084  -3.973137\n",
      " -0.8219968  -3.2203503  -1.5404993  -1.7733748   4.3071117  -1.4383297\n",
      " -5.014194   -4.935488   -2.0053065   0.0569158   4.0090446  -4.376793\n",
      " -4.8188114  -1.8175061  -2.6881125 ], shape=(39,), dtype=float32)\n",
      "loss 136546.55 reward 52.03831\n",
      "tf.Tensor(\n",
      "[ 2.913405   -6.8920603   6.549644    6.2484074  -4.137383    2.984442\n",
      "  2.6642466   0.7371458   1.7011302  -4.3962417  -2.9031067  -1.2431625\n",
      " -1.945503    6.9420786  -3.728945    1.3468748  -3.02931     4.607433\n",
      "  6.967491   -1.2192583  -2.8185296   6.1028438  -0.58411044 -4.473137\n",
      " -1.3219953  -3.7203276  -1.040525   -2.2733748   4.807108   -1.9381166\n",
      " -5.514191   -5.4354877  -1.5060705   0.5485005   4.5090375  -4.8757086\n",
      " -5.3165026  -2.317506   -3.1863868 ], shape=(39,), dtype=float32)\n",
      "loss 191079.25 reward 61.909477\n",
      "tf.Tensor(\n",
      "[ 3.413404   -7.3901567   7.049643    6.7484074  -4.634835    3.484442\n",
      "  3.1642466   0.34713632  1.2011302  -4.896144   -3.402684   -0.8660486\n",
      " -2.445503    7.4414277  -4.228945    0.8477178  -3.519173    4.107669\n",
      "  7.467491   -1.4514686  -2.3194058   5.6061625  -0.08411044 -4.973137\n",
      " -1.821995   -4.2202544  -0.54052496 -2.7733748   5.307106   -2.4380226\n",
      " -6.014189   -5.935481   -1.006073    1.048446    5.008992   -5.372577\n",
      " -5.723229   -2.817506   -3.6591477 ], shape=(39,), dtype=float32)\n",
      "loss 262826.47 reward 72.881645\n",
      "tf.Tensor(\n",
      "[ 3.913404   -7.886478    7.54964     7.2484074  -5.0925374   3.984442\n",
      "  3.6642466   0.04907209  0.70113015 -5.395016   -3.8956823  -0.3737678\n",
      " -2.945503    7.941124   -4.728945    0.3485144  -4.0190344   3.6076791\n",
      "  7.967491   -1.2775418  -1.8194062   5.106172    0.41588956 -5.473137\n",
      " -2.321995   -4.7198653  -0.04052496 -3.2733748   5.807105   -2.9379728\n",
      " -6.514186   -6.435246   -0.506073    1.548446    5.508637   -5.860608\n",
      " -5.257561   -3.317506   -3.4128945 ], shape=(39,), dtype=float32)\n",
      "loss 356214.9 reward 84.80087\n",
      "tf.Tensor(\n",
      "[ 4.4134040e+00 -8.3786287e+00  8.0496178e+00  7.7484074e+00\n",
      " -5.1387944e+00  4.4844418e+00  4.1642466e+00 -2.5370830e-01\n",
      "  2.0113015e-01 -5.8852444e+00 -4.2642269e+00  1.2601724e-01\n",
      " -3.4455030e+00  8.4409952e+00 -5.2289448e+00 -1.4991963e-01\n",
      " -4.5190330e+00  3.1076796e+00  8.4674911e+00 -8.4759808e-01\n",
      " -1.3194062e+00  4.6061721e+00  9.1588956e-01 -5.9731369e+00\n",
      " -2.8219950e+00 -5.2167559e+00  4.5947504e-01 -3.7733748e+00\n",
      "  6.3071051e+00 -3.4379506e+00 -7.0141826e+00 -6.9210591e+00\n",
      " -6.0729980e-03  2.0484462e+00  6.0060105e+00 -6.3013644e+00\n",
      " -4.7575989e+00 -3.8175061e+00 -2.9128947e+00], shape=(39,), dtype=float32)\n",
      "loss 468023.9 reward 97.209274\n",
      "tf.Tensor(\n",
      "[ 4.913404   -8.852243    8.549379    8.248407   -4.682469    4.9844418\n",
      "  4.6642466  -0.67654604 -0.29886985 -6.3222146  -3.8919568   0.626014\n",
      " -3.945503    8.940944   -5.728945   -0.6449729  -5.019033    2.6076796\n",
      "  8.967491   -0.35509166 -0.81940615  4.106172    1.4158895  -6.473137\n",
      " -3.321995   -5.6795754   0.95947504 -4.2733746   6.807105   -3.9379413\n",
      " -7.5141773  -6.6690235   0.493927    2.5484462   6.4891095  -6.003573\n",
      " -4.257599   -4.317506   -2.4128947 ], shape=(39,), dtype=float32)\n",
      "loss 596514.75 reward 109.38282\n",
      "tf.Tensor(\n",
      "[ 5.413404   -8.952429    9.046219    8.748407   -4.184133    5.4844418\n",
      "  5.1642466  -1.1433407  -0.79886985 -6.3555136  -3.3936458   1.126014\n",
      " -4.445503    9.440926   -6.228945   -1.1188791  -5.519033    2.1076796\n",
      "  9.467491    0.14455682 -0.31940615  3.606172    1.9158895  -6.973137\n",
      " -3.821995   -5.563384    1.459475   -4.7733746   7.307105   -4.4379377\n",
      " -8.014168   -6.1690235   0.993927    3.0484462   6.9397492  -5.503576\n",
      " -3.7575989  -4.817506   -1.9128947 ], shape=(39,), dtype=float32)\n",
      "loss 739427.44 reward 121.84907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[ 5.913404   -8.452429    9.505758    9.248407   -3.6841884   5.9844418\n",
      "  5.6642466  -1.6101989  -1.2988698  -5.8557196  -2.8936703   1.626014\n",
      " -4.945503    9.94092    -6.728945   -1.45469    -6.019033    1.6076796\n",
      "  9.967491    0.64454854  0.18059385  3.106172    2.4158895  -7.473137\n",
      " -4.321995   -5.063439    1.959475   -5.2733746   7.807105   -4.937937\n",
      " -8.514151   -5.6690235   1.493927    3.5484462   7.4249253  -5.003576\n",
      " -3.2575989  -5.317506   -1.4128947 ], shape=(39,), dtype=float32)\n",
      "loss 895189.3 reward 134.68948\n",
      "The Objective Value 1082.0\n",
      "tf.Tensor(\n",
      "[ 0.27450272 -0.468712   -0.23714237  0.08113994  0.29686537  0.23195691\n",
      " -0.2357221  -0.4026285   0.49510145  0.43721494  0.27811384  0.27798548\n",
      "  0.20325808 -0.35472032  0.40692502  0.49635354  0.36993057  0.21337934\n",
      "  0.22460389  0.33611527  0.29886952 -0.01669321  0.13058253  0.49785683\n",
      "  0.4610446   0.4826417   0.37055388  0.09489985  0.15529676  0.33568594\n",
      "  0.06141081  0.49836007 -0.45086414  0.4206067   0.4934658   0.48810348\n",
      "  0.11457472  0.26429772  0.44668674], shape=(39,), dtype=float32)\n",
      "loss 19460.947 reward 24.288662\n",
      "tf.Tensor(\n",
      "[ 0.46303055 -0.9296732  -0.46929342  0.26281133  0.5488537   0.544552\n",
      " -0.51930034 -0.80850595  0.9917787   0.8571032   0.535668    0.5247798\n",
      "  0.30934533 -0.6853198   0.7661117   0.9917598   0.71618474  0.42138726\n",
      "  0.47789308  0.6430652   0.51860034 -0.13561764  0.20893264  0.9941481\n",
      "  0.90730786  0.95769346  0.68041587  0.22329155  0.39669818  0.6373322\n",
      "  0.08139005  0.9955714  -0.9086187   0.81417084  0.98503494  0.97069836\n",
      "  0.2142666   0.53213537  0.89452887], shape=(39,), dtype=float32)\n",
      "loss 17588.63 reward 22.45266\n",
      "tf.Tensor(\n",
      "[ 0.46711847 -1.3805971  -0.6956297   0.5801662   0.6950291   0.9579632\n",
      " -0.87057936 -1.2210934   1.4901248   1.2166164   0.71341133  0.70004654\n",
      "  0.21677065 -0.95564497  0.95979154  1.4846846   0.9724885   0.6103427\n",
      "  0.75969094  0.8963306   0.55365235 -0.4224311   0.19126411  1.4828516\n",
      "  1.3030094   1.4089031   0.8114084   0.41736275  0.7552655   0.85048324\n",
      "  0.01712008  1.487773   -1.3729657   1.1246669   1.4731332   1.4324058\n",
      "  0.2770236   0.7846827   1.3444277 ], shape=(39,), dtype=float32)\n",
      "loss 16957.365 reward 20.822817\n",
      "tf.Tensor(\n",
      "[ 0.24615103 -1.8216217  -0.9351884   1.0001359   0.6581581   1.4311668\n",
      " -1.2856785  -1.6391156   1.9895041   1.4059446   0.7308735   0.7434871\n",
      " -0.10787392 -1.1145678   0.799337    1.9717824   1.0209593   0.7569458\n",
      "  1.0524447   1.0720887   0.3384438  -0.8467469   0.03206944  1.9292371\n",
      "  1.5614547   1.7977306   0.6229451   0.68710375  1.1971421   0.8946589\n",
      " -0.14356108  1.9568772  -1.8431252   1.239383    1.9557492   1.8227654\n",
      "  0.28423035  0.9944568   1.798628  ], shape=(39,), dtype=float32)\n",
      "loss 19668.457 reward 19.911802\n",
      "tf.Tensor(\n",
      "[-0.11240563 -2.255563   -1.2299528   1.4697996   0.41178852  1.9247926\n",
      " -1.7423673  -2.0519063   2.4893153   1.2736155   0.5440209   0.59955275\n",
      " -0.56140506 -1.1157721   0.3713731   2.4449244   0.79042053  0.81999665\n",
      "  1.3120515   1.1711295  -0.05332702 -1.3290063  -0.28115395  2.159315\n",
      "  1.5778848   2.077555    0.20538473  1.0238609   1.675921    0.7244574\n",
      " -0.365803    2.3332012  -2.3180547   1.0696754   2.4298558   2.0321715\n",
      "  0.24338563  1.1290145   2.26209   ], shape=(39,), dtype=float32)\n",
      "loss 24809.396 reward 20.818947\n",
      "tf.Tensor(\n",
      "[-0.51330477 -2.6854708  -1.6151041   1.9580622   0.02343062  2.4234295\n",
      " -2.220315   -2.4280133   2.9892619   0.88746727  0.20235279  0.2823416\n",
      " -1.0521576  -0.9571508  -0.12025875  2.8858786   0.3857658   0.74635065\n",
      "  1.4650726   1.2376629  -0.5168909  -1.8260949  -0.70185304  1.941561\n",
      "  1.382079    2.277916   -0.27887365  1.4079521   2.1668549   0.3920087\n",
      " -0.5782559   2.5125966  -2.795539    0.7011137   2.8913221   2.016437\n",
      "  0.20032199  1.1616707   2.7373216 ], shape=(39,), dtype=float32)\n",
      "loss 32394.938 reward 22.281239\n",
      "tf.Tensor(\n",
      "[-0.8816068  -3.109332   -2.07552     2.452831   -0.42922723  2.9231267\n",
      " -2.7077541  -2.6608465   3.4892452   0.4140278  -0.22020122 -0.13774452\n",
      " -1.5504622  -0.67770314 -0.61956394  3.2643774  -0.0806706   0.5019204\n",
      "  1.4273915   1.351343   -1.0028977  -2.3257706  -1.1728011   1.5004863\n",
      "  1.095364    2.521759   -0.77591634  1.8163028   2.6609805  -0.02159935\n",
      " -0.6630775   2.5409734  -3.272415    0.25158548  3.3362017   1.8852862\n",
      "  0.22998674  1.087419    3.2229137 ], shape=(39,), dtype=float32)\n",
      "loss 43270.312 reward 26.389856\n",
      "tf.Tensor(\n",
      "[-1.0356069  -3.51012    -2.567384    2.9500325  -0.9069785   3.4230442\n",
      " -3.1988826  -2.4808826   3.9892387  -0.08028945 -0.67928517 -0.60487854\n",
      " -2.050148   -0.32072243 -1.1195183   3.5481122  -0.56638956  0.11137617\n",
      "  1.1695122   1.5928701  -1.4958773  -2.825746   -1.6629909   1.0123689\n",
      "  0.8243917   2.902935   -1.2752968   2.2259355   3.154542   -0.46746457\n",
      " -0.47412825  2.5780828  -3.7459075  -0.22592455  3.7622306   1.7695246\n",
      "  0.40890673  0.9213796   3.7159994 ], shape=(39,), dtype=float32)\n",
      "loss 60445.797 reward 30.075851\n",
      "tf.Tensor(\n",
      "[-0.6940199  -3.8094368  -3.0662491   3.4483612  -1.3952981   3.9230108\n",
      " -3.6901267  -2.0096452   4.4892354  -0.5791751  -1.1558676  -1.0907568\n",
      " -2.5500863   0.08638513 -1.6195159   3.719266   -1.0590284  -0.3565903\n",
      "  0.76231396  1.9793206  -1.991144   -3.3257446  -2.1599302   0.5151601\n",
      "  0.69674885  3.3769655  -1.775147    2.6050224   3.642763   -0.9238395\n",
      " -0.05468434  2.7621958  -4.2151465  -0.7136251   4.1720304   1.7778325\n",
      "  0.7493112   0.6887493   4.21348   ], shape=(39,), dtype=float32)\n",
      "loss 81894.766 reward 35.5377\n",
      "tf.Tensor(\n",
      "[-0.20154229 -3.6156626  -3.566125    3.9472997  -1.889045    4.422987\n",
      " -4.1770215  -1.5105683   4.9892325  -1.0789957  -1.6424222  -1.5839151\n",
      " -3.0500734   0.5278952  -2.119516    3.7802587  -1.5547688  -0.85017484\n",
      "  0.29080215  2.4482503  -2.4868748  -3.8257446  -2.6590571   0.01590434\n",
      "  0.8560865   3.8738968  -2.2751052   2.8742418   4.108807   -1.3799517\n",
      "  0.4347463   3.1257231  -4.6822896  -1.2056501   4.5715523   1.9492966\n",
      "  1.1908449   0.4075615   4.7128086 ], shape=(39,), dtype=float32)\n",
      "loss 106021.414 reward 41.60894\n",
      "tf.Tensor(\n",
      "[ 0.29827538 -3.1196375  -4.0661135   4.446521   -2.3860872   4.922954\n",
      " -4.648546   -1.0105865   5.4892297  -1.5789764  -2.1362922  -2.0806012\n",
      " -3.5500705   0.9928065  -2.619516    3.7502134  -2.0520506  -1.3492516\n",
      " -0.20143747  2.9417043  -2.9811406  -4.3257446  -3.158834   -0.48388654\n",
      "  1.2559472   4.3736377  -2.7750926   2.8085132   4.458053   -1.826246\n",
      "  0.9338464   3.587581   -5.151273   -1.7002106   4.9754972   2.2218432\n",
      "  1.6743038   0.07528293  5.212653  ], shape=(39,), dtype=float32)\n",
      "loss 135829.22 reward 48.469257\n",
      "tf.Tensor(\n",
      "[ 0.7982724  -2.6196537  -4.5661125   4.9458227  -2.8848479   5.422862\n",
      " -5.0250473  -0.5105867   5.989224   -2.078975   -2.634212   -2.5791702\n",
      " -4.05007     1.4724041  -3.119516    3.6794443  -2.5500765  -1.8491563\n",
      " -0.6996645   3.4404497  -3.468955   -4.8257446  -3.658782   -0.9838197\n",
      "  1.7393572   4.873621   -3.2750883   2.3532112   4.306737   -2.2426565\n",
      "  1.4337921   4.08083    -5.624742   -2.1964161   5.4042196   2.5153823\n",
      "  2.1707757  -0.31880212  5.7126207 ], shape=(39,), dtype=float32)\n",
      "loss 171666.1 reward 55.902786\n",
      "tf.Tensor(\n",
      "[ 1.2982724  -2.1196537  -5.0661125   5.445066   -3.3843083   5.9223423\n",
      " -4.5854974  -0.01058668  6.4892054  -2.578975   -3.1336005  -3.0786686\n",
      " -4.55007     1.9598522  -3.619516    3.6752267  -3.0481882  -2.3491492\n",
      " -1.1993667   3.9402199  -3.9273283  -5.3257446  -4.15877    -1.4837883\n",
      "  2.237632    5.37362    -3.7750864   1.8552265   3.8248262  -2.5682938\n",
      "  1.93379     4.580195   -6.103024   -2.693597    5.862383    2.76338\n",
      "  2.6702664  -0.76238096  6.2126155 ], shape=(39,), dtype=float32)\n",
      "loss 209647.62 reward 63.53789\n",
      "tf.Tensor(\n",
      "[ 1.7982724  -1.6196537  -5.5661125   5.944115   -3.884029    6.415847\n",
      " -4.08555     0.48941332  6.9890876  -3.078975   -3.6334474  -3.5785363\n",
      " -5.05007     2.4514961  -4.119516    3.8833055  -3.5460954  -2.8491488\n",
      " -1.6993353   4.4401674  -4.1886816  -5.8257446  -4.658767   -1.9837611\n",
      "  2.737488    5.87362    -4.275085    1.3553355   3.3252697  -2.6854026\n",
      "  2.43379     5.080157   -6.582703   -3.1915474   6.3388405   2.7212956\n",
      "  3.170216   -1.236333    6.712615  ], shape=(39,), dtype=float32)\n",
      "loss 257239.03 reward 71.893135\n",
      "tf.Tensor(\n",
      "[ 2.2982724 -1.1196537 -6.0661125  6.44278   -4.383858   6.78179\n",
      " -3.5855498  0.9894133  7.487493  -3.578975  -4.133413  -4.078512\n",
      " -5.55007    2.9460993 -4.619516   4.3264885 -4.0435896 -3.3491488\n",
      " -2.199333   4.9401507 -3.7864451 -6.3257446 -5.1587663 -2.4837186\n",
      "  3.2374783  6.37362   -4.7750835  0.8553431  2.8252783 -2.5936978\n",
      "  2.93379    5.5801554 -7.054965  -3.6900687  6.826568   2.2580087\n",
      "  3.6702127 -1.7255578  7.212615 ], shape=(39,), dtype=float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 316366.2 reward 80.88973\n",
      "tf.Tensor(\n",
      "[ 2.7982724  -0.6196537  -6.5661125   6.9409094  -4.8837366   6.671094\n",
      " -3.0855498   1.4894133   7.945623   -4.0789747  -4.633405   -4.5785093\n",
      " -6.05007     3.442916   -5.119516    4.8213787  -4.540381   -3.8491488\n",
      " -2.6993327   5.440143   -3.2874436  -6.8257446  -5.6587663  -2.983601\n",
      "  3.7374778   6.87362    -5.2750816   0.35534382  2.3252785  -2.4402468\n",
      "  3.43379     6.0801554  -7.457798   -4.188949    7.3210096   1.7591242\n",
      "  4.1702127  -2.2214499   7.712615  ], shape=(39,), dtype=float32)\n",
      "loss 385474.5 reward 89.45334\n",
      "tf.Tensor(\n",
      "[ 3.2982724  -0.1196537  -7.0661125   7.4381633  -5.3836303   6.7389936\n",
      " -2.5855498   1.9894133   8.046541   -4.5789747  -5.1334033  -5.0785093\n",
      " -6.55007     3.9410334  -5.619516    5.3209796  -5.036133   -4.3491488\n",
      " -3.1993327   5.9401383  -2.7874477  -7.3257446  -6.1587663  -3.4830403\n",
      "  4.237478    7.37362    -5.775078   -0.14465609  1.8252785  -2.3522184\n",
      "  3.93379     6.5801554  -7.011437   -4.688064    7.818787    1.2591615\n",
      "  4.6702127  -2.7198915   8.212615  ], shape=(39,), dtype=float32)\n",
      "loss 462318.5 reward 97.69988\n",
      "tf.Tensor(\n",
      "[ 3.7982724   0.3803463  -7.5661125   7.934164   -5.8835125   7.227604\n",
      " -2.0855498   2.4894133   8.531047   -5.0789747  -5.633403   -5.5785093\n",
      " -7.05007     4.440113   -6.119516    5.820932   -5.5326853  -4.8491488\n",
      " -3.6993327   6.4401345  -2.2874477  -7.8257446  -6.6587663  -3.9783108\n",
      "  4.737478    7.87362    -6.2750664  -0.64465606  1.3252785  -2.500132\n",
      "  4.43379     7.0801554  -6.511466   -5.187444    8.317687    0.7591633\n",
      "  5.1702127  -3.2192605   8.712615  ], shape=(39,), dtype=float32)\n",
      "loss 559431.5 reward 106.43837\n",
      "tf.Tensor(\n",
      "[ 4.298272   0.8803463 -8.0661125  8.42938   -6.383357   7.7274466\n",
      " -1.5855498  2.9894133  9.030744  -5.5789747 -6.133403  -6.0785093\n",
      " -7.5500693  4.9397564 -6.619516   6.3209243 -6.030847  -5.3491488\n",
      " -4.1993327  6.9401298 -1.7874477 -8.325745  -7.1587663 -4.402503\n",
      "  5.237478   8.37362   -6.7750177 -1.1446561  0.8252785 -2.9235797\n",
      "  4.93379    7.5801554 -6.011466  -5.6870723  8.817045   0.2591634\n",
      "  5.6702127 -3.7189994  9.212615 ], shape=(39,), dtype=float32)\n",
      "loss 671383.1 reward 114.13326\n",
      "tf.Tensor(\n",
      "[ 4.798272    1.3803463  -8.5661125   8.925062   -6.8831105   8.227444\n",
      " -1.0855498   3.4894133   9.530735   -6.0789747  -6.633403   -6.5785093\n",
      " -8.050065    5.439642   -7.119516    6.8209224  -6.5301747  -5.8491488\n",
      " -4.6993327   7.4401207  -1.2874477  -8.825745   -7.6587663  -3.9215086\n",
      "  5.737478    8.87362    -7.2747383  -1.6446561   0.32527852 -3.412668\n",
      "  5.43379     8.080155   -5.511466   -6.186888    9.316586   -0.24083659\n",
      "  6.1702127  -4.2188888   9.712615  ], shape=(39,), dtype=float32)\n",
      "loss 809057.9 reward 123.679726\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for _y in range(5):\n",
    "    seed=10\n",
    "    for _a in range(200):\n",
    "    \n",
    "        for _b in range(1):\n",
    "            model.init_block(seed=seed,shuffle_bundles=True)\n",
    "            for _c in range(20):\n",
    "                stopping_cond = model.batch_train(move_num=_c)\n",
    "                if stopping_cond==0:\n",
    "                    break\n",
    "        seed+=1\n",
    "    \n",
    "    \n",
    "#     model.init_block(seed=2)\n",
    "#     for _ in range(10):\n",
    "#         stopping_cond = model.batch_train()\n",
    "#         if stopping_cond==0:\n",
    "#             break\n",
    "#     model.init_block(seed=1)\n",
    "#     for _ in range(30):\n",
    "#         model.batch_train()\n",
    "        \n",
    "#     model.init_block(seed=3)\n",
    "#     for _ in range(20):\n",
    "#         model.batch_train()\n",
    "        \n",
    "#     model.init_block(seed=4)\n",
    "#     for _ in range(20):\n",
    "#         model.batch_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3b66c0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.model.save_weights('saved_models/mip_v1_wgts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d89496f",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_bun_lkup_backup.shape\n",
    "\n",
    "model.block.bundle_availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "cfc76ab1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [367]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# model.init_block(seed=1)\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m z_bun_lkup_backup,z_ava_bun_backup,z_cur_inventory_backup,z_proba_backup \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mget_states()\n\u001b[0;32m      3\u001b[0m z_proba_backup\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 4)"
     ]
    }
   ],
   "source": [
    "# model.init_block(seed=1)\n",
    "z_bun_lkup_backup,z_ava_bun_backup,z_cur_inventory_backup,z_proba_backup = model.get_states()\n",
    "z_proba_backup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "5d4ab3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_proba  = z_proba_backup\n",
    "q_proba = tf.squeeze(q_proba)\n",
    "cur_inventory = model.block.call(q_proba,training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "77487b9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 27), dtype=float32, numpy=\n",
       "array([[26., 37., 38., 14., 10., 17., 16.,  8., 21.,  4.,  3., 16., 45.,\n",
       "        42., 37., 12.,  7.,  9., 28., 24., 26., 37., 29., 45., 49., 36.,\n",
       "        46.]], dtype=float32)>"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.block.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "bc1123e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 9), dtype=float32, numpy=\n",
       "array([[-30.550491 , -11.449804 , -43.230404 , -98.27658  , -56.970093 ,\n",
       "        -42.72441  ,  49.271088 ,  51.88796  ,  86.9891   ],\n",
       "       [ 55.4802   ,  41.43519  ,  13.639408 ,  76.63133  , 116.90954  ,\n",
       "        132.1503   ,  52.439507 ,  26.727262 ,  80.062454 ],\n",
       "       [ -8.2399645, -13.835058 , -46.898087 , -78.752785 , -94.79282  ,\n",
       "        -76.16816  , -33.326187 , -66.2751   , -80.6266   ]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reshape(cur_inventory,(3,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "eddbbe8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 13), dtype=float32, numpy=\n",
       "array([[12.692818 ,  9.968993 , 18.737873 ,  8.920593 , 10.714317 ,\n",
       "         4.5712514, 24.793142 , 17.769758 ,  6.02512  ,  9.513994 ,\n",
       "         8.371048 , 14.152736 , 15.098622 ]], dtype=float32)>"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_ava_bun_backup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e7412a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bias from target - (proposal+OH)\n",
    "# correlation between MIP solutions and RL   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4b7756d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rohan\\Anaconda3\\envs\\datasci\\lib\\site-packages\\pulp\\pulp.py:1704: UserWarning: Overwriting previously set objective.\n",
      "  warnings.warn(\"Overwriting previously set objective.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Objective Value 1023.0\n",
      "tf.Tensor([[13.  7. 12.  7.  6.  8. 18.  7.  9.  6.  7.  7. 12.]], shape=(1, 13), dtype=float32)\n",
      "tf.Tensor([[13.  7. 12.  7.  6.  8. 18.  7.  9.  6.  7.  7. 12.]], shape=(1, 13), dtype=float32)\n",
      "2.453846\n",
      "                  mip_bundle_units  rl_bundle_units\n",
      "mip_bundle_units               1.0              NaN\n",
      "rl_bundle_units                NaN              NaN\n",
      "tf.Tensor(\n",
      "[[12.699999   6.7000003 11.699999   6.7000003  5.7000003  7.7000003\n",
      "  17.699999   6.7000003  8.699999   5.7000003  6.7000003  6.7000003\n",
      "  11.699999 ]], shape=(1, 13), dtype=float32)\n",
      "2.4384615\n",
      "                  mip_bundle_units  rl_bundle_units\n",
      "mip_bundle_units               1.0              NaN\n",
      "rl_bundle_units                NaN              NaN\n",
      "tf.Tensor(\n",
      "[[12.099999  6.100001 11.099999  6.100001  5.100001  7.100001 17.099997\n",
      "   6.100001  8.099999  5.100001  6.100001  6.100001 11.099999]], shape=(1, 13), dtype=float32)\n",
      "2.4153845\n",
      "                  mip_bundle_units  rl_bundle_units\n",
      "mip_bundle_units               1.0              NaN\n",
      "rl_bundle_units                NaN              NaN\n",
      "tf.Tensor(\n",
      "[[11.199999   5.2000003 10.199999   5.2000003  4.2000003  6.2000003\n",
      "  16.199999   5.2000003  7.199999   4.2000003  5.2000003  5.2000003\n",
      "  10.199999 ]], shape=(1, 13), dtype=float32)\n",
      "2.3692305\n",
      "                  mip_bundle_units  rl_bundle_units\n",
      "mip_bundle_units          1.000000         0.292998\n",
      "rl_bundle_units           0.292998         1.000000\n",
      "tf.Tensor(\n",
      "[[10.         4.         9.         4.         3.2        5.2000003\n",
      "  15.         4.2000003  5.9999986  3.         4.2000003  4.2000003\n",
      "   9.       ]], shape=(1, 13), dtype=float32)\n",
      "2.3424556\n",
      "                  mip_bundle_units  rl_bundle_units\n",
      "mip_bundle_units          1.000000         0.345891\n",
      "rl_bundle_units           0.345891         1.000000\n",
      "tf.Tensor(\n",
      "[[ 8.5        2.5        7.7        2.7        2.1000001  4.3\n",
      "  13.7        3.1000004  4.4999986  1.9000001  3.3000004  3.4442358\n",
      "   7.7      ]], shape=(1, 13), dtype=float32)\n",
      "2.2926033\n",
      "                  mip_bundle_units  rl_bundle_units\n",
      "mip_bundle_units          1.000000         0.345242\n",
      "rl_bundle_units           0.345242         1.000000\n",
      "tf.Tensor(\n",
      "[[ 6.7000003  1.3        6.5        1.4999999  1.1000001  3.7\n",
      "  12.5        2.3000002  3.2999983  0.9        2.7000003  2.988471\n",
      "   6.7      ]], shape=(1, 13), dtype=float32)\n",
      "2.245315\n",
      "                  mip_bundle_units  rl_bundle_units\n",
      "mip_bundle_units          1.000000         0.347131\n",
      "rl_bundle_units           0.347131         1.000000\n",
      "tf.Tensor(\n",
      "[[ 5.2000003e+00  3.9999992e-01  5.5999999e+00  5.9999990e-01\n",
      "   4.0000013e-01  3.4000001e+00  1.1599999e+01  1.8000002e+00\n",
      "   2.3999984e+00 -1.1920929e-07  2.4000003e+00  2.8327062e+00\n",
      "   5.9999995e+00]], shape=(1, 13), dtype=float32)\n",
      "2.1954632\n",
      "                  mip_bundle_units  rl_bundle_units\n",
      "mip_bundle_units          1.000000         0.346489\n",
      "rl_bundle_units           0.346489         1.000000\n",
      "tf.Tensor(\n",
      "[[ 4.0000000e+00 -2.0000014e-01  5.0000000e+00 -1.1920929e-07\n",
      "   8.9406967e-08  3.4000001e+00  1.1000000e+01  1.6000001e+00\n",
      "   1.7999983e+00 -6.0000014e-01  2.4000003e+00  2.9769416e+00\n",
      "   5.5999999e+00]], shape=(1, 13), dtype=float32)\n",
      "2.1686876\n",
      "                  mip_bundle_units  rl_bundle_units\n",
      "mip_bundle_units          1.000000         0.345616\n",
      "rl_bundle_units           0.345616         1.000000\n",
      "tf.Tensor(\n",
      "[[ 3.1000001  -0.5000002   4.7        -0.30000016 -0.09999996  3.7\n",
      "  10.7         1.7         1.4999982  -0.9000002   2.7000003   3.4211767\n",
      "   5.5       ]], shape=(1, 13), dtype=float32)\n",
      "2.1444767\n",
      "                  mip_bundle_units  rl_bundle_units\n",
      "mip_bundle_units           1.00000          0.34484\n",
      "rl_bundle_units            0.34484          1.00000\n",
      "tf.Tensor(\n",
      "[[ 2.5        -0.5000002   4.7        -0.3000002   0.09999996  4.3\n",
      "  10.7         2.1         1.4999982  -0.9000002   3.3000004   4.1654115\n",
      "   5.7       ]], shape=(1, 13), dtype=float32)\n",
      "2.17924\n",
      "                  mip_bundle_units  rl_bundle_units\n",
      "mip_bundle_units          1.000000         0.349599\n",
      "rl_bundle_units           0.349599         1.000000\n",
      "tf.Tensor(\n",
      "[[ 2.2000003e+00 -2.0000020e-01  4.7999997e+00 -2.3841858e-07\n",
      "   5.9999990e-01  5.2000003e+00  1.1000000e+01  2.7999997e+00\n",
      "   1.7999983e+00 -6.0000026e-01  4.2000003e+00  5.2096472e+00\n",
      "   6.1999998e+00]], shape=(1, 13), dtype=float32)\n",
      "2.2052934\n",
      "                  mip_bundle_units  rl_bundle_units\n",
      "mip_bundle_units          1.000000         0.358304\n",
      "rl_bundle_units           0.358304         1.000000\n",
      "tf.Tensor(\n",
      "[[ 2.2000003e+00  3.9999977e-01  4.9999995e+00  5.9999973e-01\n",
      "   1.3999999e+00  6.2000003e+00  1.1599999e+01  3.7999997e+00\n",
      "   2.3999984e+00 -3.2782555e-07  5.3603354e+00  6.5538826e+00\n",
      "   6.9999995e+00]], shape=(1, 13), dtype=float32)\n",
      "2.233662\n",
      "                  mip_bundle_units  rl_bundle_units\n",
      "mip_bundle_units          1.000000         0.361026\n",
      "rl_bundle_units           0.361026         1.000000\n",
      "tf.Tensor(\n",
      "[[ 2.5         1.2999997   5.2842693   1.347136    2.4999998   7.3000007\n",
      "  12.099999    4.8999996   3.2999983   0.69999963  6.420671    7.9255075\n",
      "   7.8999996 ]], shape=(1, 13), dtype=float32)\n",
      "2.3107479\n",
      "                  mip_bundle_units  rl_bundle_units\n",
      "mip_bundle_units          1.000000         0.366774\n",
      "rl_bundle_units           0.366774         1.000000\n",
      "tf.Tensor(\n",
      "[[ 2.7        2.0999997  5.268539   1.9942724  3.4999995  8.1\n",
      "  12.299999   5.6999993  4.0999985  1.0999997  7.1810064  8.997132\n",
      "   8.499999 ]], shape=(1, 13), dtype=float32)\n",
      "2.3785856\n",
      "                  mip_bundle_units  rl_bundle_units\n",
      "mip_bundle_units          1.000000         0.370138\n",
      "rl_bundle_units           0.370138         1.000000\n",
      "tf.Tensor(\n",
      "[[ 2.8000002  2.5999994  4.9528084  2.3414087  4.222139   8.600001\n",
      "  12.2        6.1999993  4.5999985  1.1999996  7.641342   9.768757\n",
      "   8.799999 ]], shape=(1, 13), dtype=float32)\n",
      "2.4794633\n",
      "                  mip_bundle_units  rl_bundle_units\n",
      "mip_bundle_units          1.000000         0.366997\n",
      "rl_bundle_units           0.366997         1.000000\n",
      "tf.Tensor(\n",
      "[[ 2.8000002  2.9999995  4.5370784  2.5885453  4.6442785  8.800001\n",
      "  11.8        6.3999996  4.7999983  1.1999997  7.8016777 10.240381\n",
      "   8.799999 ]], shape=(1, 13), dtype=float32)\n",
      "2.5761938\n",
      "                  mip_bundle_units  rl_bundle_units\n",
      "mip_bundle_units          1.000000         0.354244\n",
      "rl_bundle_units           0.354244         1.000000\n",
      "tf.Tensor(\n",
      "[[ 2.9000003  3.2999995  4.0213485  2.7356815  4.766418   8.700001\n",
      "  11.099999   6.2999997  4.838267   1.0999997  7.662013  10.412006\n",
      "   8.499999 ]], shape=(1, 13), dtype=float32)\n",
      "2.6693764\n",
      "                  mip_bundle_units  rl_bundle_units\n",
      "mip_bundle_units           1.00000          0.32416\n",
      "rl_bundle_units            0.32416          1.00000\n",
      "tf.Tensor(\n",
      "[[ 3.3000002  3.4999995  3.6056182  2.7828178  4.7885575  8.300001\n",
      "  10.099999   6.0999994  5.176535   0.8999996  7.3839827 10.283631\n",
      "   8.099999 ]], shape=(1, 13), dtype=float32)\n",
      "2.7620072\n",
      "                  mip_bundle_units  rl_bundle_units\n",
      "mip_bundle_units          1.000000         0.281831\n",
      "rl_bundle_units           0.281831         1.000000\n",
      "tf.Tensor(\n",
      "[[ 4.          3.6722107   3.3547807   2.7299545   4.710697    7.600001\n",
      "   8.799999    5.999999    5.8148036   0.79999954  7.0059524  10.039671\n",
      "   7.5999994 ]], shape=(1, 13), dtype=float32)\n",
      "2.8556824\n",
      "                  mip_bundle_units  rl_bundle_units\n",
      "mip_bundle_units          1.000000         0.232681\n",
      "rl_bundle_units           0.232681         1.000000\n"
     ]
    }
   ],
   "source": [
    "model.init_block(seed=3)\n",
    "z_bun_lkup_backup = model.block.get_bun_sku()\n",
    "z_ava_bun_backup = model.block.get_ava_bun()\n",
    "z_cur_inventory_backup = model.block.get_cur_inv()\n",
    "z_shop_bundle_alloc_backup = model.block.get_shop_bun_alloc()\n",
    "z_proba_backup = model.block.get_shop_bun_proba()\n",
    "\n",
    "q_proba  = z_proba_backup\n",
    "print(z_ava_bun_backup)\n",
    "for _ in range(20):\n",
    "    z_bun_lkup = model.block.get_bun_sku()\n",
    "    z_ava_bun = model.block.get_ava_bun()\n",
    "    z_cur_inventory = model.block.get_cur_inv()\n",
    "    z_shop_bundle_alloc = model.block.get_shop_bun_alloc()\n",
    "    z_proba = model.block.get_shop_bun_proba()\n",
    "    #caculate the next state without training model\n",
    "    proba_update = model.model([tf.cast(z_bun_lkup,tf.float32),\n",
    "                                         tf.cast(z_ava_bun,tf.float32),\n",
    "                                         tf.cast(z_cur_inventory,tf.float32),\n",
    "                                         tf.cast(z_shop_bundle_alloc,tf.float32),\n",
    "                                         tf.cast(z_proba,tf.float32)],training=False)\n",
    "    proba_update=tf.clip_by_value(tf.squeeze(proba_update),-1.,1.)\n",
    "    \n",
    "    q_proba=tf.squeeze(z_proba)+1e-1*proba_update#tf.clip_by_value(tf.squeeze(z_proba)+1e-3*proba_update,-1,1)\n",
    "    print(z_ava_bun)\n",
    "    cur_inventory = model.block.call(q_proba,training=True)\n",
    "    \n",
    "    \n",
    "#     q_proba = tf.reshape(q_proba,[1,-1])\n",
    "\n",
    "\n",
    "#     if tf.reduce_sum(tf.cast(z_ava_bun_backup<-3,tf.float32)):\n",
    "#         print(z_ava_bun_backup)\n",
    "#         print('stopping, no available bundles')\n",
    "#         break\n",
    "\n",
    "\n",
    "#     if tf.reduce_sum(tf.cast(z_cur_inventory_backup<-3,tf.float32)):\n",
    "#         print('stopping, negative inventory')\n",
    "#         break\n",
    "\n",
    "    shop_bundle_df = pd.DataFrame(columns=('shop_id','bundle_id','mip_bundle_units','rl_bundle_units'))\n",
    "    i=0\n",
    "    for shop in model.block.shops:\n",
    "        for bundle in model.block.bundles:\n",
    "            shop_bundle_df.loc[i] = [shop,bundle,model.block.mip_shop_bundle[(shop,bundle)].numpy(),model.block.tf_alloc_shp_bun[(shop,bundle)].numpy()]\n",
    "            i+=1\n",
    "\n",
    "\n",
    "    print(abs(shop_bundle_df['mip_bundle_units']-shop_bundle_df['rl_bundle_units']).mean())\n",
    "    print(shop_bundle_df[['mip_bundle_units','rl_bundle_units']].corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "95f826cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.block.tf_alloc_shp_bun[(shop,bundle)].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6455e7f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x22eda1d4c40>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(cur_inventory.numpy().flatten(),model.block.target.numpy().flatten(),'.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "48698454",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'1': 13,\n",
       "  '2': 7,\n",
       "  '3': 12,\n",
       "  '4': 7,\n",
       "  '5': 6,\n",
       "  '6': 8,\n",
       "  '7': 18,\n",
       "  '8': 7,\n",
       "  '9': 9,\n",
       "  '10': 6,\n",
       "  '11': 7,\n",
       "  '12': 7,\n",
       "  '13': 12},\n",
       " {'1': <tf.Tensor: shape=(), dtype=float32, numpy=5.0>,\n",
       "  '2': <tf.Tensor: shape=(), dtype=float32, numpy=3.7444215>,\n",
       "  '3': <tf.Tensor: shape=(), dtype=float32, numpy=3.4039433>,\n",
       "  '4': <tf.Tensor: shape=(), dtype=float32, numpy=2.5770907>,\n",
       "  '5': <tf.Tensor: shape=(), dtype=float32, numpy=4.532837>,\n",
       "  '6': <tf.Tensor: shape=(), dtype=float32, numpy=6.600001>,\n",
       "  '7': <tf.Tensor: shape=(), dtype=float32, numpy=7.3999987>,\n",
       "  '8': <tf.Tensor: shape=(), dtype=float32, numpy=5.8569527>,\n",
       "  '9': <tf.Tensor: shape=(), dtype=float32, numpy=6.7340407>,\n",
       "  '10': <tf.Tensor: shape=(), dtype=float32, numpy=0.79999954>,\n",
       "  '11': <tf.Tensor: shape=(), dtype=float32, numpy=6.603085>,\n",
       "  '12': <tf.Tensor: shape=(), dtype=float32, numpy=9.69571>,\n",
       "  '13': <tf.Tensor: shape=(), dtype=float32, numpy=7.0353904>},\n",
       " {('1', '1'): <tf.Tensor: shape=(), dtype=float32, numpy=3.6>,\n",
       "  ('1', '2'): <tf.Tensor: shape=(), dtype=float32, numpy=2.255578>,\n",
       "  ('1', '3'): <tf.Tensor: shape=(), dtype=float32, numpy=1.4000001>,\n",
       "  ('1', '4'): <tf.Tensor: shape=(), dtype=float32, numpy=-0.5999998>,\n",
       "  ('1', '5'): <tf.Tensor: shape=(), dtype=float32, numpy=4.3999996>,\n",
       "  ('1', '6'): <tf.Tensor: shape=(), dtype=float32, numpy=2.6000001>,\n",
       "  ('1', '7'): <tf.Tensor: shape=(), dtype=float32, numpy=6.9999995>,\n",
       "  ('1', '8'): <tf.Tensor: shape=(), dtype=float32, numpy=-3.9999995>,\n",
       "  ('1', '9'): <tf.Tensor: shape=(), dtype=float32, numpy=0.019031852>,\n",
       "  ('1', '10'): <tf.Tensor: shape=(), dtype=float32, numpy=-0.5999998>,\n",
       "  ('1', '11'): <tf.Tensor: shape=(), dtype=float32, numpy=1.5150975>,\n",
       "  ('1', '12'): <tf.Tensor: shape=(), dtype=float32, numpy=-3.4191165>,\n",
       "  ('1', '13'): <tf.Tensor: shape=(), dtype=float32, numpy=1.4000001>,\n",
       "  ('2', '1'): <tf.Tensor: shape=(), dtype=float32, numpy=4.3999996>,\n",
       "  ('2', '2'): <tf.Tensor: shape=(), dtype=float32, numpy=1.2000003>,\n",
       "  ('2', '3'): <tf.Tensor: shape=(), dtype=float32, numpy=5.3960557>,\n",
       "  ('2', '4'): <tf.Tensor: shape=(), dtype=float32, numpy=1.2000003>,\n",
       "  ('2', '5'): <tf.Tensor: shape=(), dtype=float32, numpy=1.0671626>,\n",
       "  ('2', '6'): <tf.Tensor: shape=(), dtype=float32, numpy=-0.5999998>,\n",
       "  ('2', '7'): <tf.Tensor: shape=(), dtype=float32, numpy=2.6000001>,\n",
       "  ('2', '8'): <tf.Tensor: shape=(), dtype=float32, numpy=3.6000001>,\n",
       "  ('2', '9'): <tf.Tensor: shape=(), dtype=float32, numpy=0.8469256>,\n",
       "  ('2', '10'): <tf.Tensor: shape=(), dtype=float32, numpy=-1.1999998>,\n",
       "  ('2', '11'): <tf.Tensor: shape=(), dtype=float32, numpy=-2.475163>,\n",
       "  ('2', '12'): <tf.Tensor: shape=(), dtype=float32, numpy=-0.5999998>,\n",
       "  ('2', '13'): <tf.Tensor: shape=(), dtype=float32, numpy=-0.63539076>,\n",
       "  ('3', '1'): <tf.Tensor: shape=(), dtype=float32, numpy=0.0>,\n",
       "  ('3', '2'): <tf.Tensor: shape=(), dtype=float32, numpy=-0.19999978>,\n",
       "  ('3', '3'): <tf.Tensor: shape=(), dtype=float32, numpy=1.8>,\n",
       "  ('3', '4'): <tf.Tensor: shape=(), dtype=float32, numpy=3.8229086>,\n",
       "  ('3', '5'): <tf.Tensor: shape=(), dtype=float32, numpy=-3.9999995>,\n",
       "  ('3', '6'): <tf.Tensor: shape=(), dtype=float32, numpy=-0.59999967>,\n",
       "  ('3', '7'): <tf.Tensor: shape=(), dtype=float32, numpy=1.0000001>,\n",
       "  ('3', '8'): <tf.Tensor: shape=(), dtype=float32, numpy=1.5430467>,\n",
       "  ('3', '9'): <tf.Tensor: shape=(), dtype=float32, numpy=1.4000001>,\n",
       "  ('3', '10'): <tf.Tensor: shape=(), dtype=float32, numpy=7.0000005>,\n",
       "  ('3', '11'): <tf.Tensor: shape=(), dtype=float32, numpy=1.3569802>,\n",
       "  ('3', '12'): <tf.Tensor: shape=(), dtype=float32, numpy=1.3234056>,\n",
       "  ('3', '13'): <tf.Tensor: shape=(), dtype=float32, numpy=4.2000003>})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.block.bundle_availability,model.block.tf_avail_bundle,model.block.tf_alloc_shp_bun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "d46d012d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mip_bundle_units</th>\n",
       "      <th>rl_bundle_units</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mip_bundle_units</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.14642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rl_bundle_units</th>\n",
       "      <td>0.14642</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  mip_bundle_units  rl_bundle_units\n",
       "mip_bundle_units           1.00000          0.14642\n",
       "rl_bundle_units            0.14642          1.00000"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shop_bundle_df = pd.DataFrame(columns=('shop_id','bundle_id','mip_bundle_units','rl_bundle_units'))\n",
    "\n",
    "i=0\n",
    "for shop in model.block.shops:\n",
    "    for bundle in model.block.bundles:\n",
    "        shop_bundle_df.loc[i] = [shop,bundle,model.block.mip_shop_bundle[(shop,bundle)].numpy(),model.block.tf_alloc_shp_bun[(shop,bundle)].numpy()[0]]\n",
    "        i+=1\n",
    "\n",
    "\n",
    "shop_bundle_df[['mip_bundle_units','rl_bundle_units']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "ba6a7216",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mip_bundle_units</th>\n",
       "      <th>rl_bundle_units</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14.0</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.749959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>8.0</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>13.0</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>12.0</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>11.0</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mip_bundle_units  rl_bundle_units\n",
       "0                7.0         0.750000\n",
       "1                1.0         0.750000\n",
       "2                3.0         0.750000\n",
       "3                0.0         0.750000\n",
       "4               14.0         0.750000\n",
       "5                0.0         0.750000\n",
       "6                0.0         0.750000\n",
       "7               10.0         0.750000\n",
       "8                7.0         0.750000\n",
       "9                1.0         0.750000\n",
       "10               0.0         0.750000\n",
       "11               0.0         0.749959\n",
       "12               6.0         0.750000\n",
       "13               0.0         0.750000\n",
       "14               8.0         0.750000\n",
       "15               2.0         0.750000\n",
       "16               2.0         0.750000\n",
       "17               0.0         0.750000\n",
       "18               1.0         0.750000\n",
       "19               5.0         0.750000\n",
       "20               7.0         0.750000\n",
       "21               0.0         0.750000\n",
       "22               1.0         0.750000\n",
       "23               6.0         0.750000\n",
       "24               0.0         0.750000\n",
       "25              13.0         0.750000\n",
       "26               1.0         0.750000\n",
       "27               6.0         0.750000\n",
       "28               1.0         0.750000\n",
       "29              10.0         0.750000\n",
       "30               0.0         0.750000\n",
       "31              12.0         0.750000\n",
       "32              10.0         0.750000\n",
       "33               0.0         0.750000\n",
       "34               2.0         0.750000\n",
       "35               0.0         0.750000\n",
       "36              11.0         0.750000\n",
       "37               6.0         0.750000\n",
       "38               0.0         0.750000"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shop_bundle_df[['mip_bundle_units','rl_bundle_units']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 818,
   "id": "73e62a73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 818,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model.block.alloc_shp_bun[('1','1')])==tf.python.framework.ops.EagerTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "id": "de9504a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 27), dtype=float32, numpy=\n",
       "array([[ 42.006073  ,  44.501274  ,  39.56399   ,  -6.613636  ,\n",
       "         -5.8648357 ,  -7.7519836 ,  39.944504  ,  38.40349   ,\n",
       "         41.617935  ,  43.624744  ,  42.59037   ,  44.669315  ,\n",
       "         38.52914   ,  43.0463    ,  37.211     ,  42.514015  ,\n",
       "         44.368904  ,  43.938225  ,   0.72561073,   2.7990055 ,\n",
       "        -15.689171  ,  38.58704   ,  37.640587  ,  37.847088  ,\n",
       "         -3.3561106 ,  -3.5135431 ,  -7.451309  ]], dtype=float32)>"
      ]
     },
     "execution_count": 654,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_bun_lkup_backup,z_ava_bun_backup,z_cur_inventory_backup,z_shop_bun_proba_backup = model.get_states()\n",
    "\n",
    "model.block(tf.reshape(z_shop_bun_proba_backup,[-1,1]),training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "id": "b4275686",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 13), dtype=float32, numpy=\n",
       "array([[ 30.       ,  12.684504 ,  10.55661  ,  10.424743 ,  -6.6970882,\n",
       "         -5.162857 , -22.509373 ,  -2.1672878,  -3.8477821,  -2.3637257,\n",
       "         -5.171816 ,  -6.015381 ,  -4.1693707]], dtype=float32)>"
      ]
     },
     "execution_count": 657,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_ava_bun_backup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "id": "183676e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 27), dtype=float32, numpy=\n",
       "array([[ 39.006073 ,  41.501274 ,  36.56399  ,  -5.613636 ,  -4.8648357,\n",
       "         -6.751983 ,  36.944504 ,  35.40349  ,  38.617935 ,  40.624744 ,\n",
       "         39.59037  ,  41.669315 ,  35.52914  ,  40.0463   ,  34.211    ,\n",
       "         39.514015 ,  41.368904 ,  40.938225 ,   1.7256107,   3.7990055,\n",
       "        -12.689171 ,  35.58704  ,  34.640587 ,  34.847088 ,  -2.3561106,\n",
       "         -2.5135431,  -6.4513087]], dtype=float32)>"
      ]
     },
     "execution_count": 656,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_cur_inventory_backup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "id": "ca780f77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 27), dtype=float32, numpy=\n",
       "array([[38., 40., 37.,  5.,  6.,  7., 33., 30., 40., 40., 37., 40., 34.,\n",
       "        40., 31., 39., 39., 37., 14., 19., 11., 33., 32., 32., 12., 11.,\n",
       "         6.]], dtype=float32)>"
      ]
     },
     "execution_count": 655,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.block.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "id": "69c2c139",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_cur_inventory = model.block(proba_update.numpy(),training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 660,
   "id": "fbabef36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 27), dtype=float32, numpy=\n",
       "array([[ 39.328945  ,  42.76984   ,  37.88163   ,  -4.68814   ,\n",
       "         -4.004463  ,  -5.8893    ,  39.955467  ,  38.41219   ,\n",
       "         42.56997   ,  45.407833  ,  43.477192  ,  45.960827  ,\n",
       "         37.84979   ,  42.2319    ,  36.970516  ,  40.877457  ,\n",
       "         42.733765  ,  43.300728  ,   3.721553  ,   4.809765  ,\n",
       "        -11.030989  ,  36.59176   ,  35.650078  ,  35.85198   ,\n",
       "          0.19151339,   0.0793871 ,  -3.2538986 ]], dtype=float32)>"
      ]
     },
     "execution_count": 660,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_cur_inventory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "id": "8d85eb93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(1, 117), dtype=float32, numpy=\n",
       " array([[1., 1., 1., 1., 1., 1., 1., 1., 1., 3., 3., 3., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 3., 3., 3., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 3., 3., 3., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 1.]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 13), dtype=float32, numpy=\n",
       " array([[ 9., 15., 16., 12., 13., 15.,  9.,  4.,  4.,  5., 16., 11., 17.]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 27), dtype=float32, numpy=\n",
       " array([[3.9724514e-02, 2.5262414e-02, 2.4580076e-01, 1.0219672e-01,\n",
       "         2.3191391e-01, 9.2286342e-01, 9.8517412e-01, 9.7950912e-01,\n",
       "         5.3988900e-03, 1.0753026e-03, 3.1837499e-01, 7.3154479e-01,\n",
       "         9.9904364e-01, 3.4598432e-07, 9.9943691e-01, 1.9477859e-01,\n",
       "         7.0137336e-05, 2.5696063e-04, 6.5269366e-02, 8.7497741e-01,\n",
       "         9.1318679e-01, 3.8336769e-01, 4.1704030e-07, 6.6803299e-02,\n",
       "         9.4703609e-01, 6.5060490e-01, 1.2809657e-03]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 39), dtype=float32, numpy=\n",
       " array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0.]], dtype=float32)>)"
      ]
     },
     "execution_count": 429,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_bun_lkup_backup,z_ava_bun_backup,z_cur_inventory_backup,z_shop_bun_proba_backup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "43704b24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shop_id = sb_view['shop_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0c8fb10d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avail_bundle_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "718a87f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4534a3b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bundle_id</th>\n",
       "      <th>avail_bundles</th>\n",
       "      <th>is_avail</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bundle_id avail_bundles  is_avail\n",
       "0          1            10         1\n",
       "1          2            16         1\n",
       "2          3            17         1\n",
       "3          4            13         1\n",
       "4          5            14         1\n",
       "5          6            16         1\n",
       "6          7            10         1\n",
       "7          8             5         1\n",
       "8          9             5         1\n",
       "9         10             6         1\n",
       "10        11            17         1\n",
       "11        12            12         1\n",
       "12        13            15         1"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avail_bundle_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "dfda431d",
   "metadata": {},
   "outputs": [],
   "source": [
    "shop_bundle_proba_df.bundle_id = shop_bundle_proba_df.bundle_id.astype(np.str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c29fd3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "avail_bundle_df.bundle_id = avail_bundle_df.bundle_id.astype(np.str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d36ffb6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "            17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
       "            34, 35, 36, 37, 38],\n",
       "           dtype='int64')"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shop_bundle_proba_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "6f4b10b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bundle_id</th>\n",
       "      <th>avail_bundles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bundle_id avail_bundles\n",
       "0          1            10\n",
       "1          2            16\n",
       "2          3            17\n",
       "3          4            13\n",
       "4          5            14\n",
       "5          6            16\n",
       "6          7            10\n",
       "7          8             5\n",
       "8          9             5\n",
       "9         10             6\n",
       "10        11            17\n",
       "11        12            12\n",
       "12        13            18"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.avail_bundle_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "4e72463f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished allocating\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "\n",
    "    avail_bundle_df['is_avail'] = (avail_bundle_df['avail_bundles']>0).astype(np.int)\n",
    "    if avail_bundle_df['is_avail'].sum()==0:\n",
    "        print('finished allocating')\n",
    "        break\n",
    "    avail_proba_df = avail_bundle_df[['bundle_id','is_avail']].merge(shop_bundle_proba_df,on=['bundle_id'])\n",
    "    avail_proba_df.proba = avail_proba_df.proba*avail_proba_df.is_avail\n",
    "\n",
    "    sb_view = avail_proba_df[avail_proba_df.proba==avail_proba_df.proba.max()]\n",
    "\n",
    "    shop = sb_view[['shop_id']].values[0][0]\n",
    "    bundle = sb_view[['bundle_id']].values[0][0]\n",
    "\n",
    "\n",
    "    avail_bundle_num = avail_bundle_df.loc[avail_bundle_df.bundle_id==bundle,'avail_bundles'].values[0]\n",
    "    avail_bundle_df.loc[avail_bundle_df.bundle_id==bundle,'avail_bundles'] = avail_bundle_num-1\n",
    "\n",
    "    sc_units = current_inventory[shop][style+color]\n",
    "\n",
    "    for style in styles:\n",
    "        for color in colors:\n",
    "            i = current_inventory_df[(current_inventory_df.shop_id==shop)& \\\n",
    "                                     (current_inventory_df['style']==style)& \\\n",
    "                                     (current_inventory_df['color']==color)\n",
    "                                    ].index[0]\n",
    "            sc_units = current_inventory_df.loc[i,'sc_units']\n",
    "            print(sc_units)\n",
    "\n",
    "            print(bundles_static[bundle][style+color] )\n",
    "            sc_units += bundles_static[bundle][style+color] \n",
    "            print(sc_units)\n",
    "            current_inventory_df.loc[i,'sc_units'] = sc_units\n",
    "\n",
    "    #             updated_inventory_df.loc[i]=[shop,style,color,sc_units]\n",
    "    #             i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5342b134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12    17\n",
      "Name: avail_bundles, dtype: object\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "febed635",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bee58a40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shop_id</th>\n",
       "      <th>style</th>\n",
       "      <th>color</th>\n",
       "      <th>sc_units</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>C</td>\n",
       "      <td>R</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>C</td>\n",
       "      <td>B</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>C</td>\n",
       "      <td>G</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  shop_id style color sc_units\n",
       "6       1     C     R        4\n",
       "7       1     C     B        2\n",
       "8       1     C     G        4"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " current_inventory_df[(current_inventory_df.shop_id==shop)&(current_inventory_df['style']==style)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab113451",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datasci",
   "language": "python",
   "name": "datasci"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
